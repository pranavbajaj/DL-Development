{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2a8430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bajajp\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\bajajp\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import time \n",
    "from time import sleep\n",
    "import datetime\n",
    "import os \n",
    "import numpy as np \n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import TrainHelper as th\n",
    "import CustomModels as cm\n",
    "import CustomImageDataset as cid\n",
    "import LossFunction as lf \n",
    "import sys\n",
    "import glob\n",
    "sys.path.append(os.path.join('..','segment-utils'))\n",
    "import VideoAnnotationHelper as vah\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4618fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are training finetune \n",
    "fineTune = True  \n",
    "model_path = \"//cgmqnap.clearguide.local/data/Needles/Lumena/models/shaft_segmentation/model_mid_cyc_3_ep_200_bs_128_lr_0.0001_20240111_T180718finetuned.pt\"\n",
    "\n",
    "transferLearning = False   \n",
    "transfer_model_path = \"//cgmqnap.clearguide.local/data/Needles/Lumena/models/shaft_segmentation_models/model_cyc_3_ep_1000_bs_16_lr_1e-05_20230929_T060507.pt\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "cycles = 3\n",
    "\n",
    "encoder_lr = 1e-5\n",
    "decoder_lr = 1e-5\n",
    "\n",
    "lossFun = lf.IoULoss()\n",
    "\n",
    "stop_encoder_requires_grad = False\n",
    "stop_decoder_requires_grad = False\n",
    "\n",
    "parent_dir = \"C:/Lumena\"\n",
    "train_data_folder = \"train_data\"\n",
    "csv_filename = [\"cropped_256x256_original.csv\", \"cropped_256x256.csv\"]\n",
    "img_dir = [\"images_cropped_256x256_original\", \"images_cropped_256x256\"]\n",
    "mask_dir = [\"masks_cropped_256x256_original\",\"masks_cropped_256x256\"]\n",
    "\n",
    "observe_path=\"D:/test_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dffcbb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Lumena/train_data/PC2/cropped_256x256_original.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m sub_folders:\n\u001b[1;32m---> 32\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mele\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dfs)): \n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Lumena/train_data/PC2/cropped_256x256_original.csv'"
     ]
    }
   ],
   "source": [
    "#### Outlier ####\n",
    "\n",
    "sub_folders = [\"EL\", \"PC2\", \"PR\", \"EL_2\", \"CNMC\", \"CNMC.2023.11.07\", \"SS\", \"Bob\"]\n",
    "images_path_outliers = []\n",
    "labels_path_outliers = []\n",
    "\n",
    "\n",
    "for ele in sub_folders: \n",
    "    \n",
    "    i_paths = glob.glob(parent_dir + \"/\" + train_data_folder + \"/\" + ele + \"/images_outliers_cropped_256x256/*.png\")\n",
    "    m_paths = glob.glob(parent_dir + \"/\" + train_data_folder + \"/\" + ele + \"/masks_outliers_cropped_256x256/*.png\")\n",
    "    \n",
    "    images_path_outliers += i_paths \n",
    "    labels_path_outliers += m_paths \n",
    "    \n",
    "    \n",
    "# _, X1, _, y1 = train_test_split(images_path_outliers, labels_path_outliers, test_size = 0.3)\n",
    "\n",
    "X1 = images_path_outliers\n",
    "y1 = labels_path_outliers\n",
    "#### End Outlier ####\n",
    "\n",
    "#### Main Folders ####\n",
    "\n",
    "\n",
    "images_path1 = []\n",
    "labels1 = []\n",
    "\n",
    "for k in range(len(csv_filename)):\n",
    "    dfs = []\n",
    "    for ele in sub_folders:\n",
    "        df = pd.read_csv(parent_dir + \"/\" + train_data_folder + \"/\" + ele +\"/\" + csv_filename[k])\n",
    "        dfs.append(df)\n",
    "\n",
    "    for i in range(len(dfs)): \n",
    "        for name in dfs[i][\"Images\"]: \n",
    "            if name[3]:\n",
    "                label_ele = [] \n",
    "                images_path1.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + img_dir[k] + \"/\" + name)\n",
    "                labels1.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + mask_dir[k] + \"/\" + name)\n",
    "\n",
    "#_, X2, _, y2 = train_test_split(images_path1, labels1, test_size = 0.3)\n",
    "X2 = images_path1\n",
    "y2 = labels1\n",
    "\n",
    "#### End Main Folders ####\n",
    "\n",
    "#### FineTune Folders ####\n",
    "\n",
    "sub_folders = [\"PB\", \"PF\"]            \n",
    "\n",
    "images_path2 = []\n",
    "labels2 = []\n",
    "\n",
    "for k in range(len(csv_filename)):\n",
    "    dfs = []\n",
    "    for ele in sub_folders:\n",
    "        df = pd.read_csv(parent_dir + \"/\" + train_data_folder + \"/\" + ele +\"/\" + csv_filename[k])\n",
    "        dfs.append(df)\n",
    "\n",
    "    for i in range(len(dfs)): \n",
    "        for name in dfs[i][\"Images\"]: \n",
    "            if name[3]:\n",
    "                label_ele = [] \n",
    "                images_path2.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + img_dir[k] + \"/\" + name)\n",
    "                labels2.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + mask_dir[k] + \"/\" + name)\n",
    "\n",
    "# _, X3, _, y3 = train_test_split(images_path2, labels2, test_size = 0.0)\n",
    "X3 = images_path2\n",
    "y3 = labels2\n",
    "\n",
    "#### End FineTune Folders ####\n",
    "\n",
    "images_path = X1 + X2 + X3\n",
    "labels = y1 + y2 + y3\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_path, labels, test_size = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = cid.CustomImageGrayMaskDataset_dataAugmentation(X_train, y_train, ifgray = False, ifTrain = True)\n",
    "val_dataset = cid.CustomImageGrayMaskDataset_dataAugmentation(X_val, y_val, ifgray = False, ifTrain = True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True,num_workers=4,pin_memory = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False,num_workers=4,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78d8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fineTune: \n",
    "    print(\"Model loaded for finetune\")\n",
    "    model = torch.jit.load(model_path)\n",
    "else: \n",
    "    model = cm.ConvAutoEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213e097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transferLearning: \n",
    "    print(\"Old model weights transfered\")\n",
    "    old_model = torch.jit.load(transfer_model_path)\n",
    "    model.load_state_dict(old_model.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477db1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. 0 conv1.weight\n",
      "NO. 1 conv1.bias\n",
      "NO. 2 conv2.weight\n",
      "NO. 3 conv2.bias\n",
      "NO. 4 conv3.weight\n",
      "NO. 5 conv3.bias\n",
      "NO. 6 conv4.weight\n",
      "NO. 7 conv4.bias\n",
      "NO. 8 conv5.weight\n",
      "NO. 9 conv5.bias\n",
      "NO. 10 t_conv1.weight\n",
      "NO. 11 t_conv1.bias\n",
      "NO. 12 t_conv2.weight\n",
      "NO. 13 t_conv2.bias\n",
      "NO. 14 t_conv3.weight\n",
      "NO. 15 t_conv3.bias\n",
      "NO. 16 t_conv4.weight\n",
      "NO. 17 t_conv4.bias\n",
      "NO. 18 conv6.weight\n",
      "NO. 19 conv6.bias\n",
      "NO. 20 b1.weight\n",
      "NO. 21 b1.bias\n",
      "NO. 22 b2.weight\n",
      "NO. 23 b2.bias\n",
      "NO. 24 b3.weight\n",
      "NO. 25 b3.bias\n",
      "NO. 26 b4.weight\n",
      "NO. 27 b4.bias\n",
      "NO. 28 b5.weight\n",
      "NO. 29 b5.bias\n",
      "NO. 30 b6.weight\n",
      "NO. 31 b6.bias\n",
      "NO. 32 b7.weight\n",
      "NO. 33 b7.bias\n",
      "NO. 34 b8.weight\n",
      "NO. 35 b8.bias\n",
      "NO. 36 b9.weight\n",
      "NO. 37 b9.bias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"NO.\", i, name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27be364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 \n",
    "# encoder_list = []\n",
    "# decoder_list = []\n",
    "\n",
    "# for param in model.parameters(): \n",
    "#     if i < 10: \n",
    "#         if stop_encoder_requires_grad:\n",
    "#             param.requires_grad = False \n",
    "#         encoder_list.append(param)\n",
    "#     elif i < 20: \n",
    "#         if stop_decoder_requires_grad: \n",
    "#             param.requires_grad = False \n",
    "#         decoder_list.append(param)\n",
    "        \n",
    "#     i += 1\n",
    "    \n",
    "    \n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad == True:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c1d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder 'D:/test_dir/model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T094326'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model\" \n",
    "model_name += \"_cyc_\" + str(cycles) + \"_ep_\" + str(epochs) + \"_bs_\" + str(batch_size)\n",
    "model_name += \"_lr_\" + str(encoder_lr)\n",
    "model_folder = model_name +  \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now())\n",
    "\n",
    "vah.createFolder(observe_path + \"/\"  + model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49bb7a13-42cd-43f0-a809-2d31a9a6a218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7bc30d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cycle:  1\n",
      "Epoch: 0  \tTraining Loss: 0.993195 \t Vali Loss: 0.994625 \t Exe Time: 16.332732sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T094347.pt\n",
      "Epoch: 1  \tTraining Loss: 0.983302 \t Vali Loss: 0.989861 \t Exe Time: 15.269667sec\n",
      "Epoch: 2  \tTraining Loss: 0.934533 \t Vali Loss: 0.919295 \t Exe Time: 15.280990sec\n",
      "Epoch: 3  \tTraining Loss: 0.820889 \t Vali Loss: 0.830957 \t Exe Time: 15.189441sec\n",
      "Epoch: 4  \tTraining Loss: 0.743906 \t Vali Loss: 0.761357 \t Exe Time: 15.579628sec\n",
      "Epoch: 5  \tTraining Loss: 0.707007 \t Vali Loss: 0.691431 \t Exe Time: 15.377470sec\n",
      "Epoch: 6  \tTraining Loss: 0.681825 \t Vali Loss: 0.689226 \t Exe Time: 15.192897sec\n",
      "Epoch: 7  \tTraining Loss: 0.666491 \t Vali Loss: 0.743725 \t Exe Time: 15.368881sec\n",
      "Epoch: 8  \tTraining Loss: 0.656701 \t Vali Loss: 0.697139 \t Exe Time: 14.637329sec\n",
      "Epoch: 9  \tTraining Loss: 0.656763 \t Vali Loss: 0.714004 \t Exe Time: 15.010188sec\n",
      "Epoch: 10  \tTraining Loss: 0.674715 \t Vali Loss: 0.716046 \t Exe Time: 14.696806sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T094619.pt\n",
      "Epoch: 11  \tTraining Loss: 0.657347 \t Vali Loss: 0.658821 \t Exe Time: 14.441644sec\n",
      "Epoch: 12  \tTraining Loss: 0.667123 \t Vali Loss: 0.676506 \t Exe Time: 14.563407sec\n",
      "Epoch: 13  \tTraining Loss: 0.639540 \t Vali Loss: 0.684256 \t Exe Time: 14.388680sec\n",
      "Epoch: 14  \tTraining Loss: 0.636945 \t Vali Loss: 0.675642 \t Exe Time: 14.606283sec\n",
      "Epoch: 15  \tTraining Loss: 0.625050 \t Vali Loss: 0.612375 \t Exe Time: 14.809067sec\n",
      "Epoch: 16  \tTraining Loss: 0.624877 \t Vali Loss: 0.619234 \t Exe Time: 14.424931sec\n",
      "Epoch: 17  \tTraining Loss: 0.629366 \t Vali Loss: 0.598757 \t Exe Time: 14.578922sec\n",
      "Epoch: 18  \tTraining Loss: 0.638178 \t Vali Loss: 0.674593 \t Exe Time: 14.380802sec\n",
      "Epoch: 19  \tTraining Loss: 0.627266 \t Vali Loss: 0.624331 \t Exe Time: 14.403185sec\n",
      "Epoch: 20  \tTraining Loss: 0.615082 \t Vali Loss: 0.646122 \t Exe Time: 14.729927sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T094844.pt\n",
      "Epoch: 21  \tTraining Loss: 0.603402 \t Vali Loss: 0.607033 \t Exe Time: 14.166606sec\n",
      "Epoch: 22  \tTraining Loss: 0.588711 \t Vali Loss: 0.614689 \t Exe Time: 14.599806sec\n",
      "Epoch: 23  \tTraining Loss: 0.581442 \t Vali Loss: 0.590562 \t Exe Time: 14.363529sec\n",
      "Epoch: 24  \tTraining Loss: 0.594413 \t Vali Loss: 0.618753 \t Exe Time: 14.243571sec\n",
      "Epoch: 25  \tTraining Loss: 0.614830 \t Vali Loss: 0.621532 \t Exe Time: 14.580348sec\n",
      "Epoch: 26  \tTraining Loss: 0.616220 \t Vali Loss: 0.640993 \t Exe Time: 14.640697sec\n",
      "Epoch: 27  \tTraining Loss: 0.599733 \t Vali Loss: 0.575625 \t Exe Time: 14.690677sec\n",
      "Epoch: 28  \tTraining Loss: 0.591095 \t Vali Loss: 0.602071 \t Exe Time: 14.414198sec\n",
      "Epoch: 29  \tTraining Loss: 0.574868 \t Vali Loss: 0.583049 \t Exe Time: 14.475251sec\n",
      "Epoch: 30  \tTraining Loss: 0.587717 \t Vali Loss: 0.570398 \t Exe Time: 14.408456sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T095109.pt\n",
      "Epoch: 31  \tTraining Loss: 0.576200 \t Vali Loss: 0.601675 \t Exe Time: 14.523830sec\n",
      "Epoch: 32  \tTraining Loss: 0.564414 \t Vali Loss: 0.586690 \t Exe Time: 14.392447sec\n",
      "Epoch: 33  \tTraining Loss: 0.564609 \t Vali Loss: 0.576772 \t Exe Time: 14.158127sec\n",
      "Epoch: 34  \tTraining Loss: 0.578764 \t Vali Loss: 0.597193 \t Exe Time: 14.766749sec\n",
      "Epoch: 35  \tTraining Loss: 0.581115 \t Vali Loss: 0.583638 \t Exe Time: 14.859447sec\n",
      "Epoch: 36  \tTraining Loss: 0.575300 \t Vali Loss: 0.592677 \t Exe Time: 14.931777sec\n",
      "Epoch: 37  \tTraining Loss: 0.570246 \t Vali Loss: 0.594664 \t Exe Time: 14.382370sec\n",
      "Epoch: 38  \tTraining Loss: 0.566519 \t Vali Loss: 0.664349 \t Exe Time: 14.817358sec\n",
      "Epoch: 39  \tTraining Loss: 0.582854 \t Vali Loss: 0.598688 \t Exe Time: 14.035257sec\n",
      "Epoch: 40  \tTraining Loss: 0.561000 \t Vali Loss: 0.569054 \t Exe Time: 14.608340sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T095334.pt\n",
      "Epoch: 41  \tTraining Loss: 0.559367 \t Vali Loss: 0.572535 \t Exe Time: 14.680313sec\n",
      "Epoch: 42  \tTraining Loss: 0.570257 \t Vali Loss: 0.581954 \t Exe Time: 14.448370sec\n",
      "Epoch: 43  \tTraining Loss: 0.551751 \t Vali Loss: 0.524501 \t Exe Time: 14.562302sec\n",
      "Epoch: 44  \tTraining Loss: 0.579498 \t Vali Loss: 0.595830 \t Exe Time: 14.262661sec\n",
      "Epoch: 45  \tTraining Loss: 0.584119 \t Vali Loss: 0.627515 \t Exe Time: 14.195389sec\n",
      "Epoch: 46  \tTraining Loss: 0.564798 \t Vali Loss: 0.575144 \t Exe Time: 14.302089sec\n",
      "Epoch: 47  \tTraining Loss: 0.568811 \t Vali Loss: 0.637425 \t Exe Time: 14.687256sec\n",
      "Epoch: 48  \tTraining Loss: 0.571466 \t Vali Loss: 0.576707 \t Exe Time: 14.609445sec\n",
      "Epoch: 49  \tTraining Loss: 0.556561 \t Vali Loss: 0.585598 \t Exe Time: 14.161555sec\n",
      "Epoch: 50  \tTraining Loss: 0.585423 \t Vali Loss: 0.616749 \t Exe Time: 14.721511sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T095559.pt\n",
      "Epoch: 51  \tTraining Loss: 0.574556 \t Vali Loss: 0.587365 \t Exe Time: 14.430628sec\n",
      "Epoch: 52  \tTraining Loss: 0.555366 \t Vali Loss: 0.572757 \t Exe Time: 14.597680sec\n",
      "Epoch: 53  \tTraining Loss: 0.548901 \t Vali Loss: 0.537005 \t Exe Time: 14.552191sec\n",
      "Epoch: 54  \tTraining Loss: 0.541039 \t Vali Loss: 0.534496 \t Exe Time: 14.375911sec\n",
      "Epoch: 55  \tTraining Loss: 0.543465 \t Vali Loss: 0.543395 \t Exe Time: 14.443086sec\n",
      "Epoch: 56  \tTraining Loss: 0.566154 \t Vali Loss: 0.547907 \t Exe Time: 14.597814sec\n",
      "Epoch: 57  \tTraining Loss: 0.550501 \t Vali Loss: 0.571521 \t Exe Time: 14.542753sec\n",
      "Epoch: 58  \tTraining Loss: 0.556657 \t Vali Loss: 0.646828 \t Exe Time: 14.640607sec\n",
      "Epoch: 59  \tTraining Loss: 0.574730 \t Vali Loss: 0.607585 \t Exe Time: 14.434992sec\n",
      "Epoch: 60  \tTraining Loss: 0.566515 \t Vali Loss: 0.601201 \t Exe Time: 14.589048sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T095824.pt\n",
      "Epoch: 61  \tTraining Loss: 0.552155 \t Vali Loss: 0.564527 \t Exe Time: 14.885350sec\n",
      "Epoch: 62  \tTraining Loss: 0.535772 \t Vali Loss: 0.553467 \t Exe Time: 14.385450sec\n",
      "Epoch: 63  \tTraining Loss: 0.539740 \t Vali Loss: 0.537349 \t Exe Time: 14.470480sec\n",
      "Epoch: 64  \tTraining Loss: 0.544080 \t Vali Loss: 0.556906 \t Exe Time: 14.177752sec\n",
      "Early Stopping\n",
      "Training Cycle:  2\n",
      "Epoch: 0  \tTraining Loss: 0.533160 \t Vali Loss: 0.499500 \t Exe Time: 14.416352sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T095936.pt\n",
      "Epoch: 1  \tTraining Loss: 0.522029 \t Vali Loss: 0.503586 \t Exe Time: 14.116131sec\n",
      "Epoch: 2  \tTraining Loss: 0.517934 \t Vali Loss: 0.500315 \t Exe Time: 14.420542sec\n",
      "Epoch: 3  \tTraining Loss: 0.509967 \t Vali Loss: 0.501334 \t Exe Time: 14.397483sec\n",
      "Epoch: 4  \tTraining Loss: 0.509255 \t Vali Loss: 0.490322 \t Exe Time: 14.197658sec\n",
      "Epoch: 5  \tTraining Loss: 0.511441 \t Vali Loss: 0.488550 \t Exe Time: 14.601625sec\n",
      "Epoch: 6  \tTraining Loss: 0.502668 \t Vali Loss: 0.495228 \t Exe Time: 14.722519sec\n",
      "Epoch: 7  \tTraining Loss: 0.495941 \t Vali Loss: 0.482325 \t Exe Time: 14.413427sec\n",
      "Epoch: 8  \tTraining Loss: 0.498063 \t Vali Loss: 0.485789 \t Exe Time: 14.422879sec\n",
      "Epoch: 9  \tTraining Loss: 0.501412 \t Vali Loss: 0.476303 \t Exe Time: 14.391280sec\n",
      "Epoch: 10  \tTraining Loss: 0.500419 \t Vali Loss: 0.485089 \t Exe Time: 14.643255sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T100201.pt\n",
      "Epoch: 11  \tTraining Loss: 0.493721 \t Vali Loss: 0.488129 \t Exe Time: 14.488720sec\n",
      "Epoch: 12  \tTraining Loss: 0.494184 \t Vali Loss: 0.477224 \t Exe Time: 14.380766sec\n",
      "Epoch: 13  \tTraining Loss: 0.492995 \t Vali Loss: 0.469845 \t Exe Time: 14.064199sec\n",
      "Epoch: 14  \tTraining Loss: 0.493680 \t Vali Loss: 0.492714 \t Exe Time: 14.365167sec\n",
      "Epoch: 15  \tTraining Loss: 0.492178 \t Vali Loss: 0.473617 \t Exe Time: 14.602680sec\n",
      "Epoch: 16  \tTraining Loss: 0.492035 \t Vali Loss: 0.487963 \t Exe Time: 14.412615sec\n",
      "Epoch: 17  \tTraining Loss: 0.487136 \t Vali Loss: 0.482848 \t Exe Time: 14.504471sec\n",
      "Epoch: 18  \tTraining Loss: 0.492990 \t Vali Loss: 0.482183 \t Exe Time: 14.441620sec\n",
      "Epoch: 19  \tTraining Loss: 0.490115 \t Vali Loss: 0.484896 \t Exe Time: 14.454345sec\n",
      "Epoch: 20  \tTraining Loss: 0.492710 \t Vali Loss: 0.481327 \t Exe Time: 14.537372sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T100425.pt\n",
      "Epoch: 21  \tTraining Loss: 0.488353 \t Vali Loss: 0.471469 \t Exe Time: 14.594476sec\n",
      "Epoch: 22  \tTraining Loss: 0.493196 \t Vali Loss: 0.490107 \t Exe Time: 14.402245sec\n",
      "Epoch: 23  \tTraining Loss: 0.493533 \t Vali Loss: 0.468370 \t Exe Time: 14.379841sec\n",
      "Epoch: 24  \tTraining Loss: 0.486646 \t Vali Loss: 0.486967 \t Exe Time: 14.405721sec\n",
      "Epoch: 25  \tTraining Loss: 0.491025 \t Vali Loss: 0.488675 \t Exe Time: 14.387695sec\n",
      "Epoch: 26  \tTraining Loss: 0.480671 \t Vali Loss: 0.490333 \t Exe Time: 14.208979sec\n",
      "Epoch: 27  \tTraining Loss: 0.488417 \t Vali Loss: 0.473597 \t Exe Time: 14.384133sec\n",
      "Epoch: 28  \tTraining Loss: 0.488844 \t Vali Loss: 0.486500 \t Exe Time: 14.173616sec\n",
      "Epoch: 29  \tTraining Loss: 0.486238 \t Vali Loss: 0.484953 \t Exe Time: 14.750017sec\n",
      "Epoch: 30  \tTraining Loss: 0.489251 \t Vali Loss: 0.486451 \t Exe Time: 14.472884sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T100649.pt\n",
      "Epoch: 31  \tTraining Loss: 0.486457 \t Vali Loss: 0.486740 \t Exe Time: 13.966939sec\n",
      "Epoch: 32  \tTraining Loss: 0.482758 \t Vali Loss: 0.469558 \t Exe Time: 14.178007sec\n",
      "Epoch: 33  \tTraining Loss: 0.477566 \t Vali Loss: 0.482531 \t Exe Time: 14.387722sec\n",
      "Epoch: 34  \tTraining Loss: 0.487018 \t Vali Loss: 0.484219 \t Exe Time: 14.404855sec\n",
      "Epoch: 35  \tTraining Loss: 0.482018 \t Vali Loss: 0.461178 \t Exe Time: 14.774130sec\n",
      "Epoch: 36  \tTraining Loss: 0.483241 \t Vali Loss: 0.485592 \t Exe Time: 14.219555sec\n",
      "Epoch: 37  \tTraining Loss: 0.476998 \t Vali Loss: 0.470363 \t Exe Time: 14.551104sec\n",
      "Epoch: 38  \tTraining Loss: 0.485155 \t Vali Loss: 0.461894 \t Exe Time: 14.045689sec\n",
      "Epoch: 39  \tTraining Loss: 0.481583 \t Vali Loss: 0.460128 \t Exe Time: 14.319387sec\n",
      "Epoch: 40  \tTraining Loss: 0.479429 \t Vali Loss: 0.473024 \t Exe Time: 14.073303sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T100912.pt\n",
      "Epoch: 41  \tTraining Loss: 0.477677 \t Vali Loss: 0.476271 \t Exe Time: 13.933884sec\n",
      "Epoch: 42  \tTraining Loss: 0.481895 \t Vali Loss: 0.460437 \t Exe Time: 14.404354sec\n",
      "Epoch: 43  \tTraining Loss: 0.477708 \t Vali Loss: 0.471502 \t Exe Time: 14.219989sec\n",
      "Epoch: 44  \tTraining Loss: 0.474592 \t Vali Loss: 0.469742 \t Exe Time: 14.532060sec\n",
      "Epoch: 45  \tTraining Loss: 0.474616 \t Vali Loss: 0.480058 \t Exe Time: 14.650277sec\n",
      "Epoch: 46  \tTraining Loss: 0.479317 \t Vali Loss: 0.498606 \t Exe Time: 14.384879sec\n",
      "Epoch: 47  \tTraining Loss: 0.481855 \t Vali Loss: 0.485178 \t Exe Time: 13.942182sec\n",
      "Epoch: 48  \tTraining Loss: 0.473627 \t Vali Loss: 0.478402 \t Exe Time: 14.185313sec\n",
      "Epoch: 49  \tTraining Loss: 0.477254 \t Vali Loss: 0.470958 \t Exe Time: 14.189922sec\n",
      "Epoch: 50  \tTraining Loss: 0.477560 \t Vali Loss: 0.461327 \t Exe Time: 14.196548sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T101135.pt\n",
      "Epoch: 51  \tTraining Loss: 0.478553 \t Vali Loss: 0.467197 \t Exe Time: 14.014787sec\n",
      "Epoch: 52  \tTraining Loss: 0.471190 \t Vali Loss: 0.467020 \t Exe Time: 14.197457sec\n",
      "Epoch: 53  \tTraining Loss: 0.473603 \t Vali Loss: 0.467020 \t Exe Time: 14.184946sec\n",
      "Epoch: 54  \tTraining Loss: 0.477758 \t Vali Loss: 0.468722 \t Exe Time: 13.993011sec\n",
      "Epoch: 55  \tTraining Loss: 0.478609 \t Vali Loss: 0.473734 \t Exe Time: 14.390420sec\n",
      "Epoch: 56  \tTraining Loss: 0.470669 \t Vali Loss: 0.465548 \t Exe Time: 14.157383sec\n",
      "Epoch: 57  \tTraining Loss: 0.471562 \t Vali Loss: 0.469216 \t Exe Time: 14.250072sec\n",
      "Epoch: 58  \tTraining Loss: 0.470234 \t Vali Loss: 0.462287 \t Exe Time: 14.152968sec\n",
      "Epoch: 59  \tTraining Loss: 0.470430 \t Vali Loss: 0.474435 \t Exe Time: 14.047170sec\n",
      "Epoch: 60  \tTraining Loss: 0.477846 \t Vali Loss: 0.468744 \t Exe Time: 13.974310sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T101356.pt\n",
      "Epoch: 61  \tTraining Loss: 0.477480 \t Vali Loss: 0.475734 \t Exe Time: 14.372679sec\n",
      "Epoch: 62  \tTraining Loss: 0.474377 \t Vali Loss: 0.474189 \t Exe Time: 14.333465sec\n",
      "Epoch: 63  \tTraining Loss: 0.477754 \t Vali Loss: 0.496422 \t Exe Time: 14.062574sec\n",
      "Epoch: 64  \tTraining Loss: 0.475535 \t Vali Loss: 0.483161 \t Exe Time: 13.991704sec\n",
      "Epoch: 65  \tTraining Loss: 0.469688 \t Vali Loss: 0.477288 \t Exe Time: 14.388258sec\n",
      "Epoch: 66  \tTraining Loss: 0.471708 \t Vali Loss: 0.468915 \t Exe Time: 14.526274sec\n",
      "Epoch: 67  \tTraining Loss: 0.470972 \t Vali Loss: 0.481758 \t Exe Time: 14.067422sec\n",
      "Epoch: 68  \tTraining Loss: 0.471487 \t Vali Loss: 0.465499 \t Exe Time: 14.393857sec\n",
      "Epoch: 69  \tTraining Loss: 0.475571 \t Vali Loss: 0.476026 \t Exe Time: 14.191659sec\n",
      "Epoch: 70  \tTraining Loss: 0.476726 \t Vali Loss: 0.475647 \t Exe Time: 13.812215sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T101618.pt\n",
      "Epoch: 71  \tTraining Loss: 0.467146 \t Vali Loss: 0.457549 \t Exe Time: 14.156826sec\n",
      "Epoch: 72  \tTraining Loss: 0.470875 \t Vali Loss: 0.471216 \t Exe Time: 14.226238sec\n",
      "Epoch: 73  \tTraining Loss: 0.466749 \t Vali Loss: 0.485259 \t Exe Time: 14.139396sec\n",
      "Epoch: 74  \tTraining Loss: 0.466203 \t Vali Loss: 0.476171 \t Exe Time: 14.030980sec\n",
      "Epoch: 75  \tTraining Loss: 0.464387 \t Vali Loss: 0.460648 \t Exe Time: 14.383591sec\n",
      "Epoch: 76  \tTraining Loss: 0.464866 \t Vali Loss: 0.459854 \t Exe Time: 14.175477sec\n",
      "Epoch: 77  \tTraining Loss: 0.467375 \t Vali Loss: 0.464421 \t Exe Time: 14.203502sec\n",
      "Epoch: 78  \tTraining Loss: 0.461471 \t Vali Loss: 0.451674 \t Exe Time: 13.932070sec\n",
      "Epoch: 79  \tTraining Loss: 0.472804 \t Vali Loss: 0.454907 \t Exe Time: 14.245132sec\n",
      "Epoch: 80  \tTraining Loss: 0.464511 \t Vali Loss: 0.457822 \t Exe Time: 13.995875sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T101840.pt\n",
      "Epoch: 81  \tTraining Loss: 0.459175 \t Vali Loss: 0.455804 \t Exe Time: 13.956315sec\n",
      "Epoch: 82  \tTraining Loss: 0.460781 \t Vali Loss: 0.471800 \t Exe Time: 14.018704sec\n",
      "Epoch: 83  \tTraining Loss: 0.469348 \t Vali Loss: 0.465061 \t Exe Time: 13.981769sec\n",
      "Epoch: 84  \tTraining Loss: 0.467933 \t Vali Loss: 0.477010 \t Exe Time: 13.997667sec\n",
      "Epoch: 85  \tTraining Loss: 0.472084 \t Vali Loss: 0.474044 \t Exe Time: 14.145825sec\n",
      "Epoch: 86  \tTraining Loss: 0.467410 \t Vali Loss: 0.497156 \t Exe Time: 14.179754sec\n",
      "Epoch: 87  \tTraining Loss: 0.464849 \t Vali Loss: 0.495277 \t Exe Time: 14.101440sec\n",
      "Epoch: 88  \tTraining Loss: 0.465030 \t Vali Loss: 0.464097 \t Exe Time: 14.101508sec\n",
      "Epoch: 89  \tTraining Loss: 0.469087 \t Vali Loss: 0.464647 \t Exe Time: 13.671141sec\n",
      "Epoch: 90  \tTraining Loss: 0.464383 \t Vali Loss: 0.461248 \t Exe Time: 13.784441sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T102100.pt\n",
      "Epoch: 91  \tTraining Loss: 0.462615 \t Vali Loss: 0.464568 \t Exe Time: 14.095825sec\n",
      "Epoch: 92  \tTraining Loss: 0.462837 \t Vali Loss: 0.475742 \t Exe Time: 14.054809sec\n",
      "Epoch: 93  \tTraining Loss: 0.454766 \t Vali Loss: 0.472583 \t Exe Time: 14.183176sec\n",
      "Epoch: 94  \tTraining Loss: 0.452426 \t Vali Loss: 0.465917 \t Exe Time: 13.947944sec\n",
      "Epoch: 95  \tTraining Loss: 0.465279 \t Vali Loss: 0.463517 \t Exe Time: 13.872518sec\n",
      "Epoch: 96  \tTraining Loss: 0.477366 \t Vali Loss: 0.476213 \t Exe Time: 14.514859sec\n",
      "Epoch: 97  \tTraining Loss: 0.461954 \t Vali Loss: 0.460334 \t Exe Time: 14.061244sec\n",
      "Epoch: 98  \tTraining Loss: 0.460699 \t Vali Loss: 0.459506 \t Exe Time: 14.189067sec\n",
      "Epoch: 99  \tTraining Loss: 0.467112 \t Vali Loss: 0.475119 \t Exe Time: 14.367963sec\n",
      "Epoch: 100  \tTraining Loss: 0.468670 \t Vali Loss: 0.488379 \t Exe Time: 14.219623sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T102322.pt\n",
      "Epoch: 101  \tTraining Loss: 0.463775 \t Vali Loss: 0.461883 \t Exe Time: 13.940948sec\n",
      "Epoch: 102  \tTraining Loss: 0.463465 \t Vali Loss: 0.455590 \t Exe Time: 14.159344sec\n",
      "Epoch: 103  \tTraining Loss: 0.460885 \t Vali Loss: 0.471948 \t Exe Time: 14.225590sec\n",
      "Epoch: 104  \tTraining Loss: 0.459052 \t Vali Loss: 0.472324 \t Exe Time: 14.136747sec\n",
      "Epoch: 105  \tTraining Loss: 0.463288 \t Vali Loss: 0.469002 \t Exe Time: 13.849869sec\n",
      "Early Stopping\n",
      "Training Cycle:  3\n",
      "Epoch: 0  \tTraining Loss: 0.462932 \t Vali Loss: 0.453328 \t Exe Time: 14.141405sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T102446.pt\n",
      "Epoch: 1  \tTraining Loss: 0.461834 \t Vali Loss: 0.466189 \t Exe Time: 14.032161sec\n",
      "Epoch: 2  \tTraining Loss: 0.459768 \t Vali Loss: 0.451918 \t Exe Time: 14.203967sec\n",
      "Epoch: 3  \tTraining Loss: 0.457334 \t Vali Loss: 0.459205 \t Exe Time: 14.395574sec\n",
      "Epoch: 4  \tTraining Loss: 0.456331 \t Vali Loss: 0.446602 \t Exe Time: 14.204386sec\n",
      "Epoch: 5  \tTraining Loss: 0.458662 \t Vali Loss: 0.458572 \t Exe Time: 13.943715sec\n",
      "Epoch: 6  \tTraining Loss: 0.458736 \t Vali Loss: 0.475810 \t Exe Time: 14.043026sec\n",
      "Epoch: 7  \tTraining Loss: 0.460070 \t Vali Loss: 0.452768 \t Exe Time: 14.332773sec\n",
      "Epoch: 8  \tTraining Loss: 0.465274 \t Vali Loss: 0.452022 \t Exe Time: 13.848734sec\n",
      "Epoch: 9  \tTraining Loss: 0.460902 \t Vali Loss: 0.465528 \t Exe Time: 13.946320sec\n",
      "Epoch: 10  \tTraining Loss: 0.449520 \t Vali Loss: 0.454246 \t Exe Time: 14.049871sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T102707.pt\n",
      "Epoch: 11  \tTraining Loss: 0.457321 \t Vali Loss: 0.450423 \t Exe Time: 14.156678sec\n",
      "Epoch: 12  \tTraining Loss: 0.458428 \t Vali Loss: 0.450069 \t Exe Time: 14.177015sec\n",
      "Epoch: 13  \tTraining Loss: 0.465971 \t Vali Loss: 0.444359 \t Exe Time: 14.197039sec\n",
      "Epoch: 14  \tTraining Loss: 0.462586 \t Vali Loss: 0.462536 \t Exe Time: 14.401191sec\n",
      "Epoch: 15  \tTraining Loss: 0.456034 \t Vali Loss: 0.455293 \t Exe Time: 14.125557sec\n",
      "Epoch: 16  \tTraining Loss: 0.455795 \t Vali Loss: 0.462398 \t Exe Time: 14.473285sec\n",
      "Epoch: 17  \tTraining Loss: 0.460626 \t Vali Loss: 0.465859 \t Exe Time: 13.924681sec\n",
      "Epoch: 18  \tTraining Loss: 0.461589 \t Vali Loss: 0.449893 \t Exe Time: 14.245008sec\n",
      "Epoch: 19  \tTraining Loss: 0.452724 \t Vali Loss: 0.455336 \t Exe Time: 14.217640sec\n",
      "Epoch: 20  \tTraining Loss: 0.455072 \t Vali Loss: 0.457168 \t Exe Time: 14.175252sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T102929.pt\n",
      "Epoch: 21  \tTraining Loss: 0.456143 \t Vali Loss: 0.456192 \t Exe Time: 14.358859sec\n",
      "Epoch: 22  \tTraining Loss: 0.455636 \t Vali Loss: 0.466040 \t Exe Time: 14.206001sec\n",
      "Epoch: 23  \tTraining Loss: 0.454975 \t Vali Loss: 0.449527 \t Exe Time: 13.943578sec\n",
      "Epoch: 24  \tTraining Loss: 0.458194 \t Vali Loss: 0.463773 \t Exe Time: 14.033940sec\n",
      "Epoch: 25  \tTraining Loss: 0.455000 \t Vali Loss: 0.451494 \t Exe Time: 14.198379sec\n",
      "Epoch: 26  \tTraining Loss: 0.455922 \t Vali Loss: 0.460878 \t Exe Time: 14.350576sec\n",
      "Epoch: 27  \tTraining Loss: 0.456980 \t Vali Loss: 0.448599 \t Exe Time: 14.051756sec\n",
      "Epoch: 28  \tTraining Loss: 0.448342 \t Vali Loss: 0.459462 \t Exe Time: 14.183912sec\n",
      "Epoch: 29  \tTraining Loss: 0.452113 \t Vali Loss: 0.458160 \t Exe Time: 14.146081sec\n",
      "Epoch: 30  \tTraining Loss: 0.447910 \t Vali Loss: 0.447542 \t Exe Time: 14.051132sec\n",
      "Temprary model saved:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T103151.pt\n",
      "Epoch: 31  \tTraining Loss: 0.454414 \t Vali Loss: 0.454060 \t Exe Time: 14.100496sec\n",
      "Epoch: 32  \tTraining Loss: 0.453205 \t Vali Loss: 0.458338 \t Exe Time: 14.046092sec\n",
      "Epoch: 33  \tTraining Loss: 0.456522 \t Vali Loss: 0.457685 \t Exe Time: 13.991756sec\n",
      "Epoch: 34  \tTraining Loss: 0.456385 \t Vali Loss: 0.468365 \t Exe Time: 13.987495sec\n",
      "Epoch: 35  \tTraining Loss: 0.454978 \t Vali Loss: 0.481485 \t Exe Time: 14.179375sec\n",
      "Epoch: 36  \tTraining Loss: 0.455826 \t Vali Loss: 0.464127 \t Exe Time: 14.186694sec\n",
      "Epoch: 37  \tTraining Loss: 0.450862 \t Vali Loss: 0.474819 \t Exe Time: 14.382831sec\n",
      "Epoch: 38  \tTraining Loss: 0.454307 \t Vali Loss: 0.479534 \t Exe Time: 13.865172sec\n",
      "Epoch: 39  \tTraining Loss: 0.457619 \t Vali Loss: 0.453394 \t Exe Time: 13.970960sec\n",
      "Epoch: 40  \tTraining Loss: 0.456238 \t Vali Loss: 0.471198 \t Exe Time: 13.947362sec\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "for j in range(cycles):\n",
    "        \n",
    "    print(\"Training Cycle: \", j+1)\n",
    "\n",
    "#     optimizer = torch.optim.Adam([{\"params\":encoder_list, \"lr\":encoder_lr},\n",
    "#                                   {\"params\":decoder_list, \"lr\":decoder_lr}\n",
    "#                                  ])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = encoder_lr)\n",
    "    \n",
    "    early_stopping = th.EarlyStopping(patience = 20, min_delta = 0.01)\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        start_time = time.time() \n",
    "        \n",
    "        model.train()\n",
    "        for data in train_loader: \n",
    "\n",
    "             \n",
    "            images, labels = data \n",
    "            images = images.to(device)\n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "\n",
    "            loss = lossFun.forward(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval() \n",
    "        for data in val_loader: \n",
    "\n",
    "            \n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels= labels.to(device)\n",
    "            with torch.no_grad(): \n",
    "                outputs = model(images)\n",
    "                loss = lossFun.forward(outputs,labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss/len(train_loader)    \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "\n",
    "        print('Epoch: {}  \\tTraining Loss: {:.6f} \\t Vali Loss: {:.6f} \\t Exe Time: {:.6f}sec'.format(\n",
    "        epoch, \n",
    "        train_loss, \n",
    "        val_loss,\n",
    "        time.time() - start_time))\n",
    "\n",
    "        stop = early_stopping.early_stop(val_loss, model)\n",
    "        if stop: \n",
    "            model = early_stopping.get_model() \n",
    "            print(\"Early Stopping\")\n",
    "            encoder_lr /= 10\n",
    "            decoder_lr /= 10\n",
    "            break \n",
    "\n",
    "        if epoch % 10 == 0: \n",
    "\n",
    "            model_script = torch.jit.script(model)\n",
    "            temp_name = model_name + \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now()) + \".pt\"\n",
    "            model_script.save(observe_path + \"/\"  + model_folder + \"/\" + temp_name)\n",
    "            print(\"Temprary model saved: \", temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b49fa533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model:  model_cyc_3_ep_200_bs_128_lr_0.001_20240112_T103411.pt\n"
     ]
    }
   ],
   "source": [
    "model_script = torch.jit.script(model)\n",
    "final_model = model_name + \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now())\n",
    "if fineTune: \n",
    "    final_model += \"finetuned.pt\"\n",
    "else: \n",
    "    final_model += \".pt\"\n",
    "\n",
    "model_script.save(\"//cgmqnap.clearguide.local/data/Needles/Lumena\" + \"/models/shaft_segmentation/\" + final_model)\n",
    "print(\"Saved trained model: \", final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aac726-0d4e-40aa-9238-2b09401531f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
