{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3c9ddf-7c0f-4781-8d28-3dae2c389617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bajajp\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\bajajp\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\bajajp\\appdata\\local\\anaconda3\\envs\\xmen\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time \n",
    "from time import sleep\n",
    "import datetime\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np \n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import TrainHelper as th\n",
    "import CustomModels as cm\n",
    "import CustomImageDataset as cid\n",
    "import torch.nn.functional as F\n",
    "import LossFunction as lf \n",
    "import sys\n",
    "import glob \n",
    "from torchvision.transforms.v2 import GaussianBlur\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append(os.path.join('..','segment-utils'))\n",
    "import VideoAnnotationHelper as vah\n",
    "\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4878725-775f-4ef6-9a06-fcf713d5aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "noHub_dir = \"C:/Lumena/train_data/NH/\"\n",
    "images1 = glob.glob(noHub_dir + \"images_cropped_256x256/*.png\")\n",
    "labels1 = []\n",
    "label_paths = glob.glob(noHub_dir + \"masksLined_cropped_256x256/*.png\")\n",
    "for k in range(len(label_paths)):\n",
    "    ele = []\n",
    "    ele.append(label_paths[k])\n",
    "    ele.append((-1, -1,-1,-1,0))\n",
    "    labels1.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e10de7-8f64-4d5a-b11e-3dc8ad00d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "noHub_dir = \"C:/Lumena/train_data/NH2/\"\n",
    "images2 = glob.glob(noHub_dir + \"images_cropped_256x256/*.png\")\n",
    "labels2 = []\n",
    "label_paths = glob.glob(noHub_dir + \"masksLined_cropped_256x256/*.png\")\n",
    "for k in range(len(label_paths)):\n",
    "    ele = []\n",
    "    ele.append(label_paths[k])\n",
    "    ele.append((-1, -1,-1,-1,0))\n",
    "    labels2.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0274cd61-db8f-4461-8a28-d820652ed1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTune = True  \n",
    "model_path = \"//cgmqnap.clearguide.local/data/Needles/Lumena/models/hub_regression/model_cyc_1_ep_400_bs_32_lr_0.0001_20231228_T171234.pt\"\n",
    "\n",
    "parent_dir = \"C:/Lumena\"\n",
    "train_data_folder = \"train_data\"\n",
    "sub_folders = [\"EL\", \"PC2\", \"PR\", \"EL_2\", \"CNMC\", \"CNMC.2023.11.07\", \"SS\"]\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "cycles = 1 \n",
    "\n",
    "encoder_lr = 1e-4  \n",
    "regA_lr = 1e-4\n",
    "regB_lr = 1e-6\n",
    "\n",
    "stop_encoder_requires_grad = True    \n",
    "stop_regA_requires_grad = True  \n",
    "stop_regB_requires_grad = False  \n",
    "\n",
    "FullRange = False \n",
    "Gray = False\n",
    "ifTrain = True \n",
    "AddMskCha = True \n",
    "\n",
    "observe_path=\"D:/test_dir\"\n",
    "\n",
    "old_model_path = \"//cgmqnap.clearguide.local/data/Needles/Lumena/models/shaft_segmentation_models/3ChaInpute_RegARegBCombined_20231116_T124859.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60de422-4d69-45d0-93f3-cf0c0226c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = [\"cropped_256x256.csv\"]\n",
    "img_dir = [\"images_cropped_256x256\"]\n",
    "mask_dir = [\"masksLined_cropped_256x256\"]\n",
    "\n",
    "images3 = []\n",
    "labels3 = []\n",
    "\n",
    "for k in range(len(csv_filename)):\n",
    "    dfs = []\n",
    "    for ele in sub_folders:\n",
    "        df = pd.read_csv(parent_dir + \"/\" + train_data_folder + \"/\" + ele +\"/\" + csv_filename[k])\n",
    "        dfs.append(df)\n",
    "\n",
    "    for i in range(len(dfs)): \n",
    "        for name in zip(dfs[i][\"Images\"]):  \n",
    "            label_ele = [] \n",
    "            images3.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + img_dir[k] + \"/\" + name[0])\n",
    "            label_ele.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + mask_dir[k] + \"/\" + name[0])\n",
    "            label_ele.append((-1,-1,-1,-1,1))\n",
    "            labels3.append(label_ele)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe32f25-2fb5-48c6-a11b-066d164a842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = [\"no_hub_cropped_256x256.csv\"]\n",
    "img_dir = [\"images_no_hub_cropped_256x256\"]\n",
    "mask_dir = [\"masksLined_no_hub_cropped_256x256\"]\n",
    "\n",
    "images4 = []\n",
    "labels4 = []\n",
    "\n",
    "for k in range(len(csv_filename)):\n",
    "    dfs = []\n",
    "    for ele in sub_folders:\n",
    "        df = pd.read_csv(parent_dir + \"/\" + train_data_folder + \"/\" + ele +\"/\" + csv_filename[k])\n",
    "        dfs.append(df)\n",
    "\n",
    "    for i in range(len(dfs)): \n",
    "        for name in zip(dfs[i][\"Images\"]): \n",
    "            label_ele = [] \n",
    "            images4.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + img_dir[k] + \"/\" + name[0])\n",
    "            label_ele.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + mask_dir[k] + \"/\" + name[0])\n",
    "            label_ele.append((-1,-1,-1,-1,0))\n",
    "            labels4.append(label_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe52f000-0528-41f0-9b4f-82b9b6350a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "images4, _, labels4, _ = train_test_split(images4, labels4, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5adb800-7c1d-4a8d-9000-fb214457f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = images1 + images2 + images3 + images4\n",
    "labels = labels1 + labels2 + labels3 + labels4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefdbb10-3d27-4fc5-b7f9-616ba95de027",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images_path, labels, test_size = 0.2)\n",
    "\n",
    "train_dataset = cid.Custom_ImageRegressor_Dataset2(X_train, y_train, ifgray = Gray, ifTrain = ifTrain, ifFullRange = FullRange, ifAddMskCha = AddMskCha)\n",
    "val_dataset = cid.Custom_ImageRegressor_Dataset2(X_val, y_val, ifgray = Gray, ifTrain = ifTrain, ifFullRange = FullRange, ifAddMskCha = AddMskCha)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True,num_workers=4,pin_memory = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False,num_workers=4,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cd2a70-cd36-4f7c-8156-6b5778801238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder 'D:/test_dir/model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T114613'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model\" \n",
    "model_name += \"_cyc_\" + str(cycles) + \"_ep_\" + str(epochs) + \"_bs_\" + str(batch_size)\n",
    "model_name += \"_lr_\" + str(regA_lr)\n",
    "model_folder = model_name +  \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now())\n",
    " \n",
    "vah.createFolder(observe_path + \"/\"  + model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4675895-e60e-415f-b0e0-6b116ea9ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded for finetune\n"
     ]
    }
   ],
   "source": [
    "if fineTune: \n",
    "    print(\"Model loaded for finetune\")\n",
    "    model = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fdf230b-b63d-42cd-a026-cbc8045fd291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. 0 conv1.0.conv_block.0.conv_block.0.weight\n",
      "NO. 1 conv1.0.conv_block.0.conv_block.0.bias\n",
      "NO. 2 conv1.0.conv_block.0.conv_block.1.weight\n",
      "NO. 3 conv1.0.conv_block.0.conv_block.1.bias\n",
      "NO. 4 conv1.1.conv_block.0.conv_block.0.weight\n",
      "NO. 5 conv1.1.conv_block.0.conv_block.0.bias\n",
      "NO. 6 conv1.1.conv_block.0.conv_block.1.weight\n",
      "NO. 7 conv1.1.conv_block.0.conv_block.1.bias\n",
      "NO. 8 conv2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 9 conv2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 10 conv2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 11 conv2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 12 conv2.1.conv_block.0.conv_block.0.weight\n",
      "NO. 13 conv2.1.conv_block.0.conv_block.0.bias\n",
      "NO. 14 conv2.1.conv_block.0.conv_block.1.weight\n",
      "NO. 15 conv2.1.conv_block.0.conv_block.1.bias\n",
      "NO. 16 conv3.0.layer.0.group1.conv_block.0.weight\n",
      "NO. 17 conv3.0.layer.0.group1.conv_block.0.bias\n",
      "NO. 18 conv3.0.layer.0.group1.conv_block.1.weight\n",
      "NO. 19 conv3.0.layer.0.group1.conv_block.1.bias\n",
      "NO. 20 conv3.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 21 conv3.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 22 conv3.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 23 conv3.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 24 conv3.0.layer.0.group2.1.conv_block.0.weight\n",
      "NO. 25 conv3.0.layer.0.group2.1.conv_block.0.bias\n",
      "NO. 26 conv3.0.layer.0.group2.1.conv_block.1.weight\n",
      "NO. 27 conv3.0.layer.0.group2.1.conv_block.1.bias\n",
      "NO. 28 conv3.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "NO. 29 conv3.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "NO. 30 conv3.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "NO. 31 conv3.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "NO. 32 conv3.0.layer.0.group3.1.conv_block.0.weight\n",
      "NO. 33 conv3.0.layer.0.group3.1.conv_block.0.bias\n",
      "NO. 34 conv3.0.layer.0.group3.1.conv_block.1.weight\n",
      "NO. 35 conv3.0.layer.0.group3.1.conv_block.1.bias\n",
      "NO. 36 conv3.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "NO. 37 conv3.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "NO. 38 conv3.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "NO. 39 conv3.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "NO. 40 conv3.0.layer.0.group4.1.conv_block.0.weight\n",
      "NO. 41 conv3.0.layer.0.group4.1.conv_block.0.bias\n",
      "NO. 42 conv3.0.layer.0.group4.1.conv_block.1.weight\n",
      "NO. 43 conv3.0.layer.0.group4.1.conv_block.1.bias\n",
      "NO. 44 conv3.1.residual_layer.0.residual_layer.0.weight\n",
      "NO. 45 conv3.1.residual_layer.0.residual_layer.0.bias\n",
      "NO. 46 conv3.1.residual_layer.0.residual_layer.1.weight\n",
      "NO. 47 conv3.1.residual_layer.0.residual_layer.1.bias\n",
      "NO. 48 conv4_h.0.layer.0.group1.conv_block.0.weight\n",
      "NO. 49 conv4_h.0.layer.0.group1.conv_block.0.bias\n",
      "NO. 50 conv4_h.0.layer.0.group1.conv_block.1.weight\n",
      "NO. 51 conv4_h.0.layer.0.group1.conv_block.1.bias\n",
      "NO. 52 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 53 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 54 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 55 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 56 conv4_h.0.layer.0.group2.1.conv_block.0.weight\n",
      "NO. 57 conv4_h.0.layer.0.group2.1.conv_block.0.bias\n",
      "NO. 58 conv4_h.0.layer.0.group2.1.conv_block.1.weight\n",
      "NO. 59 conv4_h.0.layer.0.group2.1.conv_block.1.bias\n",
      "NO. 60 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "NO. 61 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "NO. 62 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "NO. 63 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "NO. 64 conv4_h.0.layer.0.group3.1.conv_block.0.weight\n",
      "NO. 65 conv4_h.0.layer.0.group3.1.conv_block.0.bias\n",
      "NO. 66 conv4_h.0.layer.0.group3.1.conv_block.1.weight\n",
      "NO. 67 conv4_h.0.layer.0.group3.1.conv_block.1.bias\n",
      "NO. 68 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "NO. 69 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "NO. 70 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "NO. 71 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "NO. 72 conv4_h.0.layer.0.group4.1.conv_block.0.weight\n",
      "NO. 73 conv4_h.0.layer.0.group4.1.conv_block.0.bias\n",
      "NO. 74 conv4_h.0.layer.0.group4.1.conv_block.1.weight\n",
      "NO. 75 conv4_h.0.layer.0.group4.1.conv_block.1.bias\n",
      "NO. 76 conv4_h.1.residual_layer.0.residual_layer.0.weight\n",
      "NO. 77 conv4_h.1.residual_layer.0.residual_layer.0.bias\n",
      "NO. 78 conv4_h.1.residual_layer.0.residual_layer.1.weight\n",
      "NO. 79 conv4_h.1.residual_layer.0.residual_layer.1.bias\n",
      "NO. 80 conv4_t.0.layer.0.group1.conv_block.0.weight\n",
      "NO. 81 conv4_t.0.layer.0.group1.conv_block.0.bias\n",
      "NO. 82 conv4_t.0.layer.0.group1.conv_block.1.weight\n",
      "NO. 83 conv4_t.0.layer.0.group1.conv_block.1.bias\n",
      "NO. 84 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 85 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 86 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 87 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 88 conv4_t.0.layer.0.group2.1.conv_block.0.weight\n",
      "NO. 89 conv4_t.0.layer.0.group2.1.conv_block.0.bias\n",
      "NO. 90 conv4_t.0.layer.0.group2.1.conv_block.1.weight\n",
      "NO. 91 conv4_t.0.layer.0.group2.1.conv_block.1.bias\n",
      "NO. 92 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "NO. 93 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "NO. 94 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "NO. 95 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "NO. 96 conv4_t.0.layer.0.group3.1.conv_block.0.weight\n",
      "NO. 97 conv4_t.0.layer.0.group3.1.conv_block.0.bias\n",
      "NO. 98 conv4_t.0.layer.0.group3.1.conv_block.1.weight\n",
      "NO. 99 conv4_t.0.layer.0.group3.1.conv_block.1.bias\n",
      "NO. 100 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "NO. 101 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "NO. 102 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "NO. 103 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "NO. 104 conv4_t.0.layer.0.group4.1.conv_block.0.weight\n",
      "NO. 105 conv4_t.0.layer.0.group4.1.conv_block.0.bias\n",
      "NO. 106 conv4_t.0.layer.0.group4.1.conv_block.1.weight\n",
      "NO. 107 conv4_t.0.layer.0.group4.1.conv_block.1.bias\n",
      "NO. 108 conv4_t.1.residual_layer.0.residual_layer.0.weight\n",
      "NO. 109 conv4_t.1.residual_layer.0.residual_layer.0.bias\n",
      "NO. 110 conv4_t.1.residual_layer.0.residual_layer.1.weight\n",
      "NO. 111 conv4_t.1.residual_layer.0.residual_layer.1.bias\n",
      "NO. 112 fcah.0.weight\n",
      "NO. 113 fcah.0.bias\n",
      "NO. 114 fcah.1.weight\n",
      "NO. 115 fcah.1.bias\n",
      "NO. 116 fcah.3.weight\n",
      "NO. 117 fcah.3.bias\n",
      "NO. 118 fcah.4.weight\n",
      "NO. 119 fcah.4.bias\n",
      "NO. 120 fcah.6.weight\n",
      "NO. 121 fcah.6.bias\n",
      "NO. 122 fcah.7.weight\n",
      "NO. 123 fcah.7.bias\n",
      "NO. 124 fcah.9.weight\n",
      "NO. 125 fcah.9.bias\n",
      "NO. 126 fcat.0.weight\n",
      "NO. 127 fcat.0.bias\n",
      "NO. 128 fcat.1.weight\n",
      "NO. 129 fcat.1.bias\n",
      "NO. 130 fcat.3.weight\n",
      "NO. 131 fcat.3.bias\n",
      "NO. 132 fcat.4.weight\n",
      "NO. 133 fcat.4.bias\n",
      "NO. 134 fcat.6.weight\n",
      "NO. 135 fcat.6.bias\n",
      "NO. 136 fcat.7.weight\n",
      "NO. 137 fcat.7.bias\n",
      "NO. 138 fcat.9.weight\n",
      "NO. 139 fcat.9.bias\n",
      "NO. 140 fcb.0.weight\n",
      "NO. 141 fcb.0.bias\n",
      "NO. 142 fcb.1.weight\n",
      "NO. 143 fcb.1.bias\n",
      "NO. 144 fcb.3.weight\n",
      "NO. 145 fcb.3.bias\n",
      "NO. 146 fcb.4.weight\n",
      "NO. 147 fcb.4.bias\n",
      "NO. 148 fcb.6.weight\n",
      "NO. 149 fcb.6.bias\n",
      "NO. 150 fcb.7.weight\n",
      "NO. 151 fcb.7.bias\n",
      "NO. 152 fcb.9.weight\n",
      "NO. 153 fcb.9.bias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"NO.\", i, name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a80edf1-5a74-47c9-bc56-79d2cd3bc904",
   "metadata": {},
   "outputs": [],
   "source": [
    " i = 0 \n",
    "encoder_list = []\n",
    "regressorA_list = []\n",
    "regressorB_list = [] \n",
    "\n",
    "for param in model.parameters(): \n",
    "    if i < 112: \n",
    "        if stop_encoder_requires_grad:\n",
    "            param.requires_grad = False \n",
    "        encoder_list.append(param)\n",
    "    elif i < 140: \n",
    "        if stop_regA_requires_grad: \n",
    "            param.requires_grad = False \n",
    "        regressorA_list.append(param)\n",
    "    else: \n",
    "        if stop_regB_requires_grad: \n",
    "            param.requires_grad = False \n",
    "        regressorB_list.append(param)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15112df9-522a-45cf-a8e2-fd512da91ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcb.0.weight\n",
      "fcb.0.bias\n",
      "fcb.1.weight\n",
      "fcb.1.bias\n",
      "fcb.3.weight\n",
      "fcb.3.bias\n",
      "fcb.4.weight\n",
      "fcb.4.bias\n",
      "fcb.6.weight\n",
      "fcb.6.bias\n",
      "fcb.7.weight\n",
      "fcb.7.bias\n",
      "fcb.9.weight\n",
      "fcb.9.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9924fa0-694c-4a49-8cdb-3e6f31ed8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    " lossFun1 = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9add97dc-a70d-4238-93d9-d58fa3946770",
   "metadata": {},
   "outputs": [],
   "source": [
    " regB_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a97d06-bf71-42a7-8b97-d0526ba02b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cycle:  1\n",
      "Epoch: 0  \tTraining Loss: 0.358357 \t Vali Loss: 0.278641 \t Exe Time: 25.254119sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T114641.pt\n",
      "Epoch: 1  \tTraining Loss: 0.292989 \t Vali Loss: 0.268150 \t Exe Time: 15.518880sec\n",
      "Epoch: 2  \tTraining Loss: 0.279812 \t Vali Loss: 0.270083 \t Exe Time: 15.512229sec\n",
      "Epoch: 3  \tTraining Loss: 0.270842 \t Vali Loss: 0.263631 \t Exe Time: 15.316238sec\n",
      "Epoch: 4  \tTraining Loss: 0.259621 \t Vali Loss: 0.257873 \t Exe Time: 15.300140sec\n",
      "Epoch: 5  \tTraining Loss: 0.250651 \t Vali Loss: 0.248484 \t Exe Time: 15.218940sec\n",
      "Epoch: 6  \tTraining Loss: 0.241521 \t Vali Loss: 0.241823 \t Exe Time: 15.394868sec\n",
      "Epoch: 7  \tTraining Loss: 0.234424 \t Vali Loss: 0.238206 \t Exe Time: 15.279839sec\n",
      "Epoch: 8  \tTraining Loss: 0.226636 \t Vali Loss: 0.230219 \t Exe Time: 15.294105sec\n",
      "Epoch: 9  \tTraining Loss: 0.219226 \t Vali Loss: 0.224520 \t Exe Time: 15.183533sec\n",
      "Epoch: 10  \tTraining Loss: 0.211877 \t Vali Loss: 0.216498 \t Exe Time: 15.392917sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T114915.pt\n",
      "Epoch: 11  \tTraining Loss: 0.205907 \t Vali Loss: 0.210726 \t Exe Time: 15.564699sec\n",
      "Epoch: 12  \tTraining Loss: 0.199419 \t Vali Loss: 0.205968 \t Exe Time: 15.142595sec\n",
      "Epoch: 13  \tTraining Loss: 0.193812 \t Vali Loss: 0.198983 \t Exe Time: 15.311197sec\n",
      "Epoch: 14  \tTraining Loss: 0.187978 \t Vali Loss: 0.193818 \t Exe Time: 15.368322sec\n",
      "Epoch: 15  \tTraining Loss: 0.183018 \t Vali Loss: 0.188182 \t Exe Time: 15.910321sec\n",
      "Epoch: 16  \tTraining Loss: 0.178540 \t Vali Loss: 0.183047 \t Exe Time: 15.171023sec\n",
      "Epoch: 17  \tTraining Loss: 0.171609 \t Vali Loss: 0.181323 \t Exe Time: 15.272848sec\n",
      "Epoch: 18  \tTraining Loss: 0.167427 \t Vali Loss: 0.175233 \t Exe Time: 15.298204sec\n",
      "Epoch: 19  \tTraining Loss: 0.163684 \t Vali Loss: 0.169778 \t Exe Time: 14.983565sec\n",
      "Epoch: 20  \tTraining Loss: 0.158314 \t Vali Loss: 0.163807 \t Exe Time: 15.047819sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T115148.pt\n",
      "Epoch: 21  \tTraining Loss: 0.152122 \t Vali Loss: 0.161495 \t Exe Time: 15.304711sec\n",
      "Epoch: 22  \tTraining Loss: 0.148493 \t Vali Loss: 0.155229 \t Exe Time: 15.454068sec\n",
      "Epoch: 23  \tTraining Loss: 0.144830 \t Vali Loss: 0.153251 \t Exe Time: 15.333995sec\n",
      "Epoch: 24  \tTraining Loss: 0.140371 \t Vali Loss: 0.152403 \t Exe Time: 15.570860sec\n",
      "Epoch: 25  \tTraining Loss: 0.137116 \t Vali Loss: 0.146214 \t Exe Time: 15.117216sec\n",
      "Epoch: 26  \tTraining Loss: 0.133349 \t Vali Loss: 0.139768 \t Exe Time: 15.174468sec\n",
      "Epoch: 27  \tTraining Loss: 0.129502 \t Vali Loss: 0.137833 \t Exe Time: 15.250470sec\n",
      "Epoch: 28  \tTraining Loss: 0.125937 \t Vali Loss: 0.134719 \t Exe Time: 15.453249sec\n",
      "Epoch: 29  \tTraining Loss: 0.122821 \t Vali Loss: 0.133488 \t Exe Time: 15.278363sec\n",
      "Epoch: 30  \tTraining Loss: 0.118578 \t Vali Loss: 0.127992 \t Exe Time: 15.248639sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T115421.pt\n",
      "Epoch: 31  \tTraining Loss: 0.115473 \t Vali Loss: 0.126277 \t Exe Time: 15.251264sec\n",
      "Epoch: 32  \tTraining Loss: 0.112514 \t Vali Loss: 0.128088 \t Exe Time: 15.747466sec\n",
      "Epoch: 33  \tTraining Loss: 0.109871 \t Vali Loss: 0.118431 \t Exe Time: 15.355485sec\n",
      "Epoch: 34  \tTraining Loss: 0.107672 \t Vali Loss: 0.117482 \t Exe Time: 14.899278sec\n",
      "Epoch: 35  \tTraining Loss: 0.103831 \t Vali Loss: 0.114823 \t Exe Time: 14.966529sec\n",
      "Epoch: 36  \tTraining Loss: 0.101462 \t Vali Loss: 0.111983 \t Exe Time: 15.483426sec\n",
      "Epoch: 37  \tTraining Loss: 0.098314 \t Vali Loss: 0.109232 \t Exe Time: 15.599837sec\n",
      "Epoch: 38  \tTraining Loss: 0.095698 \t Vali Loss: 0.100824 \t Exe Time: 15.434537sec\n",
      "Epoch: 39  \tTraining Loss: 0.092952 \t Vali Loss: 0.114097 \t Exe Time: 15.730672sec\n",
      "Epoch: 40  \tTraining Loss: 0.091390 \t Vali Loss: 0.104417 \t Exe Time: 15.154653sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T115655.pt\n",
      "Epoch: 41  \tTraining Loss: 0.088496 \t Vali Loss: 0.099450 \t Exe Time: 15.288065sec\n",
      "Epoch: 42  \tTraining Loss: 0.086095 \t Vali Loss: 0.098814 \t Exe Time: 15.516411sec\n",
      "Epoch: 43  \tTraining Loss: 0.083967 \t Vali Loss: 0.096048 \t Exe Time: 15.178802sec\n",
      "Epoch: 44  \tTraining Loss: 0.081866 \t Vali Loss: 0.090933 \t Exe Time: 15.415837sec\n",
      "Epoch: 45  \tTraining Loss: 0.082622 \t Vali Loss: 0.094564 \t Exe Time: 15.264904sec\n",
      "Epoch: 46  \tTraining Loss: 0.078792 \t Vali Loss: 0.094995 \t Exe Time: 15.316692sec\n",
      "Epoch: 47  \tTraining Loss: 0.076888 \t Vali Loss: 0.094899 \t Exe Time: 15.373204sec\n",
      "Epoch: 48  \tTraining Loss: 0.074183 \t Vali Loss: 0.089078 \t Exe Time: 15.384747sec\n",
      "Epoch: 49  \tTraining Loss: 0.072872 \t Vali Loss: 0.084411 \t Exe Time: 15.512728sec\n",
      "Epoch: 50  \tTraining Loss: 0.071031 \t Vali Loss: 0.083191 \t Exe Time: 15.231736sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T115929.pt\n",
      "Epoch: 51  \tTraining Loss: 0.067964 \t Vali Loss: 0.080156 \t Exe Time: 15.657195sec\n",
      "Epoch: 52  \tTraining Loss: 0.067384 \t Vali Loss: 0.076039 \t Exe Time: 15.223551sec\n",
      "Epoch: 53  \tTraining Loss: 0.065428 \t Vali Loss: 0.082288 \t Exe Time: 15.669392sec\n",
      "Epoch: 54  \tTraining Loss: 0.064271 \t Vali Loss: 0.076147 \t Exe Time: 15.254215sec\n",
      "Epoch: 55  \tTraining Loss: 0.062793 \t Vali Loss: 0.073357 \t Exe Time: 15.216340sec\n",
      "Epoch: 56  \tTraining Loss: 0.061218 \t Vali Loss: 0.074851 \t Exe Time: 15.252678sec\n",
      "Epoch: 57  \tTraining Loss: 0.059721 \t Vali Loss: 0.072703 \t Exe Time: 15.183135sec\n",
      "Epoch: 58  \tTraining Loss: 0.057811 \t Vali Loss: 0.066796 \t Exe Time: 15.252237sec\n",
      "Epoch: 59  \tTraining Loss: 0.056717 \t Vali Loss: 0.071059 \t Exe Time: 15.334917sec\n",
      "Epoch: 60  \tTraining Loss: 0.055673 \t Vali Loss: 0.071229 \t Exe Time: 15.327870sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T120202.pt\n",
      "Epoch: 61  \tTraining Loss: 0.054307 \t Vali Loss: 0.064485 \t Exe Time: 15.487593sec\n",
      "Epoch: 62  \tTraining Loss: 0.052649 \t Vali Loss: 0.060510 \t Exe Time: 15.405355sec\n",
      "Epoch: 63  \tTraining Loss: 0.051839 \t Vali Loss: 0.065407 \t Exe Time: 15.034379sec\n",
      "Epoch: 64  \tTraining Loss: 0.050527 \t Vali Loss: 0.065799 \t Exe Time: 15.300689sec\n",
      "Epoch: 65  \tTraining Loss: 0.048929 \t Vali Loss: 0.067229 \t Exe Time: 15.358044sec\n",
      "Epoch: 66  \tTraining Loss: 0.048281 \t Vali Loss: 0.057893 \t Exe Time: 15.462188sec\n",
      "Epoch: 67  \tTraining Loss: 0.047801 \t Vali Loss: 0.061701 \t Exe Time: 15.432352sec\n",
      "Epoch: 68  \tTraining Loss: 0.046396 \t Vali Loss: 0.061269 \t Exe Time: 15.446525sec\n",
      "Epoch: 69  \tTraining Loss: 0.045201 \t Vali Loss: 0.064184 \t Exe Time: 15.030024sec\n",
      "Epoch: 70  \tTraining Loss: 0.043416 \t Vali Loss: 0.058013 \t Exe Time: 15.320133sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T120436.pt\n",
      "Epoch: 71  \tTraining Loss: 0.043421 \t Vali Loss: 0.059977 \t Exe Time: 15.336290sec\n",
      "Epoch: 72  \tTraining Loss: 0.042137 \t Vali Loss: 0.054535 \t Exe Time: 15.668694sec\n",
      "Epoch: 73  \tTraining Loss: 0.041276 \t Vali Loss: 0.054463 \t Exe Time: 15.323387sec\n",
      "Epoch: 74  \tTraining Loss: 0.040123 \t Vali Loss: 0.060115 \t Exe Time: 15.529293sec\n",
      "Epoch: 75  \tTraining Loss: 0.039650 \t Vali Loss: 0.053955 \t Exe Time: 15.317432sec\n",
      "Epoch: 76  \tTraining Loss: 0.038809 \t Vali Loss: 0.054526 \t Exe Time: 15.248983sec\n",
      "Epoch: 77  \tTraining Loss: 0.037415 \t Vali Loss: 0.050424 \t Exe Time: 15.528066sec\n",
      "Epoch: 78  \tTraining Loss: 0.037033 \t Vali Loss: 0.047975 \t Exe Time: 15.382761sec\n",
      "Epoch: 79  \tTraining Loss: 0.036137 \t Vali Loss: 0.049741 \t Exe Time: 15.198750sec\n",
      "Epoch: 80  \tTraining Loss: 0.035038 \t Vali Loss: 0.046611 \t Exe Time: 15.469260sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T120710.pt\n",
      "Epoch: 81  \tTraining Loss: 0.034937 \t Vali Loss: 0.050243 \t Exe Time: 15.184333sec\n",
      "Epoch: 82  \tTraining Loss: 0.034427 \t Vali Loss: 0.045755 \t Exe Time: 15.511988sec\n",
      "Epoch: 83  \tTraining Loss: 0.033178 \t Vali Loss: 0.049138 \t Exe Time: 14.963374sec\n",
      "Epoch: 84  \tTraining Loss: 0.032332 \t Vali Loss: 0.049160 \t Exe Time: 15.241872sec\n",
      "Epoch: 85  \tTraining Loss: 0.031853 \t Vali Loss: 0.048986 \t Exe Time: 15.623095sec\n",
      "Epoch: 86  \tTraining Loss: 0.031135 \t Vali Loss: 0.043026 \t Exe Time: 15.203870sec\n",
      "Epoch: 87  \tTraining Loss: 0.030820 \t Vali Loss: 0.042886 \t Exe Time: 15.235435sec\n",
      "Epoch: 88  \tTraining Loss: 0.029996 \t Vali Loss: 0.040525 \t Exe Time: 15.029195sec\n",
      "Epoch: 89  \tTraining Loss: 0.029579 \t Vali Loss: 0.047472 \t Exe Time: 15.300196sec\n",
      "Epoch: 90  \tTraining Loss: 0.029094 \t Vali Loss: 0.048947 \t Exe Time: 15.092923sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T120943.pt\n",
      "Epoch: 91  \tTraining Loss: 0.027985 \t Vali Loss: 0.041246 \t Exe Time: 15.244255sec\n",
      "Epoch: 92  \tTraining Loss: 0.027466 \t Vali Loss: 0.044064 \t Exe Time: 15.204668sec\n",
      "Epoch: 93  \tTraining Loss: 0.027122 \t Vali Loss: 0.044136 \t Exe Time: 15.244571sec\n",
      "Epoch: 94  \tTraining Loss: 0.026152 \t Vali Loss: 0.051359 \t Exe Time: 15.540265sec\n",
      "Epoch: 95  \tTraining Loss: 0.025672 \t Vali Loss: 0.040920 \t Exe Time: 15.616376sec\n",
      "Epoch: 96  \tTraining Loss: 0.025694 \t Vali Loss: 0.042971 \t Exe Time: 15.391811sec\n",
      "Epoch: 97  \tTraining Loss: 0.025340 \t Vali Loss: 0.039010 \t Exe Time: 15.196615sec\n",
      "Epoch: 98  \tTraining Loss: 0.024195 \t Vali Loss: 0.039853 \t Exe Time: 15.041451sec\n",
      "Epoch: 99  \tTraining Loss: 0.023903 \t Vali Loss: 0.043503 \t Exe Time: 15.339345sec\n",
      "Epoch: 100  \tTraining Loss: 0.023780 \t Vali Loss: 0.041366 \t Exe Time: 15.301834sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T121216.pt\n",
      "Epoch: 101  \tTraining Loss: 0.023578 \t Vali Loss: 0.040521 \t Exe Time: 15.408780sec\n",
      "Epoch: 102  \tTraining Loss: 0.022629 \t Vali Loss: 0.041827 \t Exe Time: 15.609962sec\n",
      "Epoch: 103  \tTraining Loss: 0.022354 \t Vali Loss: 0.040554 \t Exe Time: 15.407995sec\n",
      "Epoch: 104  \tTraining Loss: 0.021762 \t Vali Loss: 0.040279 \t Exe Time: 15.219660sec\n",
      "Epoch: 105  \tTraining Loss: 0.021174 \t Vali Loss: 0.038597 \t Exe Time: 15.521998sec\n",
      "Epoch: 106  \tTraining Loss: 0.021118 \t Vali Loss: 0.041581 \t Exe Time: 15.190048sec\n",
      "Epoch: 107  \tTraining Loss: 0.020805 \t Vali Loss: 0.037622 \t Exe Time: 15.251061sec\n",
      "Epoch: 108  \tTraining Loss: 0.020315 \t Vali Loss: 0.033468 \t Exe Time: 14.988001sec\n",
      "Epoch: 109  \tTraining Loss: 0.019809 \t Vali Loss: 0.040623 \t Exe Time: 15.170424sec\n",
      "Epoch: 110  \tTraining Loss: 0.019626 \t Vali Loss: 0.031247 \t Exe Time: 15.123204sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T121449.pt\n",
      "Epoch: 111  \tTraining Loss: 0.019009 \t Vali Loss: 0.036142 \t Exe Time: 15.506784sec\n",
      "Epoch: 112  \tTraining Loss: 0.018609 \t Vali Loss: 0.037251 \t Exe Time: 15.453007sec\n",
      "Epoch: 113  \tTraining Loss: 0.018489 \t Vali Loss: 0.034194 \t Exe Time: 15.294712sec\n",
      "Epoch: 114  \tTraining Loss: 0.019778 \t Vali Loss: 0.037569 \t Exe Time: 15.395634sec\n",
      "Epoch: 115  \tTraining Loss: 0.020426 \t Vali Loss: 0.055351 \t Exe Time: 15.509341sec\n",
      "Epoch: 116  \tTraining Loss: 0.028218 \t Vali Loss: 0.044312 \t Exe Time: 15.511845sec\n",
      "Epoch: 117  \tTraining Loss: 0.024236 \t Vali Loss: 0.034696 \t Exe Time: 15.511243sec\n",
      "Epoch: 118  \tTraining Loss: 0.021589 \t Vali Loss: 0.048953 \t Exe Time: 15.630733sec\n",
      "Epoch: 119  \tTraining Loss: 0.018516 \t Vali Loss: 0.033862 \t Exe Time: 15.055186sec\n",
      "Epoch: 120  \tTraining Loss: 0.018651 \t Vali Loss: 0.024264 \t Exe Time: 15.390106sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T121723.pt\n",
      "Epoch: 121  \tTraining Loss: 0.019112 \t Vali Loss: 0.032591 \t Exe Time: 15.216932sec\n",
      "Epoch: 122  \tTraining Loss: 0.016403 \t Vali Loss: 0.024460 \t Exe Time: 15.104412sec\n",
      "Epoch: 123  \tTraining Loss: 0.015598 \t Vali Loss: 0.034160 \t Exe Time: 15.204899sec\n",
      "Epoch: 124  \tTraining Loss: 0.015929 \t Vali Loss: 0.026332 \t Exe Time: 15.190649sec\n",
      "Epoch: 125  \tTraining Loss: 0.015083 \t Vali Loss: 0.034546 \t Exe Time: 15.294568sec\n",
      "Epoch: 126  \tTraining Loss: 0.015172 \t Vali Loss: 0.030264 \t Exe Time: 15.270422sec\n",
      "Epoch: 127  \tTraining Loss: 0.015776 \t Vali Loss: 0.022803 \t Exe Time: 15.277550sec\n",
      "Epoch: 128  \tTraining Loss: 0.014939 \t Vali Loss: 0.036910 \t Exe Time: 15.272458sec\n",
      "Epoch: 129  \tTraining Loss: 0.013731 \t Vali Loss: 0.032637 \t Exe Time: 15.572456sec\n",
      "Epoch: 130  \tTraining Loss: 0.013491 \t Vali Loss: 0.021644 \t Exe Time: 15.479616sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T121956.pt\n",
      "Epoch: 131  \tTraining Loss: 0.013344 \t Vali Loss: 0.027362 \t Exe Time: 15.302930sec\n",
      "Epoch: 132  \tTraining Loss: 0.012974 \t Vali Loss: 0.029696 \t Exe Time: 15.281967sec\n",
      "Epoch: 133  \tTraining Loss: 0.012948 \t Vali Loss: 0.036737 \t Exe Time: 15.132768sec\n",
      "Epoch: 134  \tTraining Loss: 0.012770 \t Vali Loss: 0.031935 \t Exe Time: 15.391811sec\n",
      "Epoch: 135  \tTraining Loss: 0.012617 \t Vali Loss: 0.019203 \t Exe Time: 15.184766sec\n",
      "Epoch: 136  \tTraining Loss: 0.012708 \t Vali Loss: 0.029895 \t Exe Time: 15.499540sec\n",
      "Epoch: 137  \tTraining Loss: 0.014504 \t Vali Loss: 0.017016 \t Exe Time: 15.490788sec\n",
      "Epoch: 138  \tTraining Loss: 0.013652 \t Vali Loss: 0.025895 \t Exe Time: 15.379346sec\n",
      "Epoch: 139  \tTraining Loss: 0.012225 \t Vali Loss: 0.017705 \t Exe Time: 15.170017sec\n",
      "Epoch: 140  \tTraining Loss: 0.011606 \t Vali Loss: 0.030763 \t Exe Time: 15.602817sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T122230.pt\n",
      "Epoch: 141  \tTraining Loss: 0.011138 \t Vali Loss: 0.028653 \t Exe Time: 15.652918sec\n",
      "Epoch: 142  \tTraining Loss: 0.010702 \t Vali Loss: 0.030911 \t Exe Time: 15.267866sec\n",
      "Epoch: 143  \tTraining Loss: 0.010541 \t Vali Loss: 0.028642 \t Exe Time: 15.341668sec\n",
      "Epoch: 144  \tTraining Loss: 0.010501 \t Vali Loss: 0.024956 \t Exe Time: 14.994049sec\n",
      "Epoch: 145  \tTraining Loss: 0.010343 \t Vali Loss: 0.023789 \t Exe Time: 15.338581sec\n",
      "Epoch: 146  \tTraining Loss: 0.010289 \t Vali Loss: 0.022615 \t Exe Time: 15.198908sec\n",
      "Epoch: 147  \tTraining Loss: 0.010185 \t Vali Loss: 0.017713 \t Exe Time: 15.390460sec\n",
      "Epoch: 148  \tTraining Loss: 0.010486 \t Vali Loss: 0.028097 \t Exe Time: 15.139741sec\n",
      "Epoch: 149  \tTraining Loss: 0.009651 \t Vali Loss: 0.024677 \t Exe Time: 15.252006sec\n",
      "Epoch: 150  \tTraining Loss: 0.009510 \t Vali Loss: 0.030262 \t Exe Time: 14.986381sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T122503.pt\n",
      "Epoch: 151  \tTraining Loss: 0.009261 \t Vali Loss: 0.017988 \t Exe Time: 15.516370sec\n",
      "Epoch: 152  \tTraining Loss: 0.009094 \t Vali Loss: 0.017241 \t Exe Time: 14.921597sec\n",
      "Epoch: 153  \tTraining Loss: 0.009013 \t Vali Loss: 0.028687 \t Exe Time: 15.703010sec\n",
      "Epoch: 154  \tTraining Loss: 0.008921 \t Vali Loss: 0.017152 \t Exe Time: 15.255396sec\n",
      "Epoch: 155  \tTraining Loss: 0.009103 \t Vali Loss: 0.021628 \t Exe Time: 15.396444sec\n",
      "Epoch: 156  \tTraining Loss: 0.008585 \t Vali Loss: 0.016357 \t Exe Time: 15.313790sec\n",
      "Epoch: 157  \tTraining Loss: 0.008441 \t Vali Loss: 0.018570 \t Exe Time: 15.444004sec\n",
      "Epoch: 158  \tTraining Loss: 0.008266 \t Vali Loss: 0.017738 \t Exe Time: 15.092181sec\n",
      "Epoch: 159  \tTraining Loss: 0.008007 \t Vali Loss: 0.033535 \t Exe Time: 15.143934sec\n",
      "Epoch: 160  \tTraining Loss: 0.008183 \t Vali Loss: 0.028335 \t Exe Time: 15.132102sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T122736.pt\n",
      "Epoch: 161  \tTraining Loss: 0.007991 \t Vali Loss: 0.028663 \t Exe Time: 15.203860sec\n",
      "Epoch: 162  \tTraining Loss: 0.007744 \t Vali Loss: 0.022805 \t Exe Time: 15.806768sec\n",
      "Epoch: 163  \tTraining Loss: 0.007713 \t Vali Loss: 0.032725 \t Exe Time: 15.233064sec\n",
      "Epoch: 164  \tTraining Loss: 0.007890 \t Vali Loss: 0.019648 \t Exe Time: 15.103086sec\n",
      "Epoch: 165  \tTraining Loss: 0.007397 \t Vali Loss: 0.028100 \t Exe Time: 15.594026sec\n",
      "Epoch: 166  \tTraining Loss: 0.007376 \t Vali Loss: 0.023808 \t Exe Time: 15.259490sec\n",
      "Epoch: 167  \tTraining Loss: 0.007588 \t Vali Loss: 0.025554 \t Exe Time: 14.922396sec\n",
      "Epoch: 168  \tTraining Loss: 0.007038 \t Vali Loss: 0.026920 \t Exe Time: 15.326429sec\n",
      "Epoch: 169  \tTraining Loss: 0.007061 \t Vali Loss: 0.023044 \t Exe Time: 15.727288sec\n",
      "Epoch: 170  \tTraining Loss: 0.006829 \t Vali Loss: 0.022708 \t Exe Time: 15.046326sec\n",
      "Temprary model saved:  model_cyc_1_ep_200_bs_128_lr_0.0001_20240105_T123009.pt\n",
      "Epoch: 171  \tTraining Loss: 0.006923 \t Vali Loss: 0.019197 \t Exe Time: 14.945328sec\n",
      "Epoch: 172  \tTraining Loss: 0.006450 \t Vali Loss: 0.025487 \t Exe Time: 15.189414sec\n",
      "Epoch: 173  \tTraining Loss: 0.006831 \t Vali Loss: 0.013029 \t Exe Time: 15.054146sec\n",
      "Epoch: 174  \tTraining Loss: 0.006751 \t Vali Loss: 0.028327 \t Exe Time: 15.169104sec\n",
      "Epoch: 175  \tTraining Loss: 0.007199 \t Vali Loss: 0.018635 \t Exe Time: 15.126295sec\n",
      "Epoch: 176  \tTraining Loss: 0.011172 \t Vali Loss: 0.020090 \t Exe Time: 15.286764sec\n",
      "Epoch: 177  \tTraining Loss: 0.007207 \t Vali Loss: 0.020958 \t Exe Time: 15.421607sec\n",
      "Epoch: 178  \tTraining Loss: 0.006162 \t Vali Loss: 0.026363 \t Exe Time: 15.407969sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss1\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()    \n\u001b[1;32m---> 34\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_yx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(cycles):\n",
    "\n",
    "    print(\"Training Cycle: \", j+1)\n",
    "\n",
    "    optimizer = torch.optim.Adam([#{\"params\":encoder_list, \"lr\":encoder_lr},\n",
    "                                 {\"params\":regressorB_list, \"lr\":regB_lr},])\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0        \n",
    "        start_time = time.time() \n",
    "        \n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            images, true_yx, true_p= data \n",
    "            timex = time.process_time()\n",
    "            images = images.to(device)\n",
    "            true_p = true_p.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_yx, pred_p = model(images)\n",
    "\n",
    "            loss1 = lossFun1.forward(pred_p.float(),true_p.float())\n",
    "            \n",
    "            #print(loss1.item())\n",
    "            \n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss1\n",
    "\n",
    "            \n",
    "        model.eval()    \n",
    "        for data in val_loader: \n",
    "            \n",
    "            images, true_yx, true_p= data\n",
    "            images = images.to(device)\n",
    "            true_p = true_p.to(device)\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                pred_yx, pred_p = model(images)\n",
    "                loss1 = lossFun1.forward(pred_p.float(),true_p.float())\n",
    "                \n",
    "            val_loss += loss1\n",
    "\n",
    "        \n",
    "        train_loss = train_loss/len(train_loader)    \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        \n",
    "        \n",
    "        print('Epoch: {}  \\tTraining Loss: {:.6f} \\t Vali Loss: {:.6f} \\t Exe Time: {:.6f}sec'.format(\n",
    "        epoch, \n",
    "        train_loss, \n",
    "        val_loss,\n",
    "        time.time() - start_time))\n",
    "        \n",
    "        if epoch % 10 == 0: \n",
    " \n",
    "            model_script = torch.jit.script(model)\n",
    "            temp_name = model_name + \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now()) + \".pt\"\n",
    "            model_script.save(observe_path + \"/\"  + model_folder + \"/\" + temp_name)\n",
    "            print(\"Temprary model saved: \", temp_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536693b-aadd-4d09-8e9c-59686bdcf8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
