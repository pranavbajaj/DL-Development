{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b56b10-d031-44da-a3f6-be77fef05451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bajajp\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\bajajp\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time \n",
    "from time import sleep\n",
    "import datetime\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np \n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import TrainHelper as th\n",
    "import CustomModels as cm\n",
    "import CustomHubModels as chm\n",
    "import CustomImageDataset as cid\n",
    "import torch.nn.functional as F\n",
    "import LossFunction as lf \n",
    "import HubLossFunctions as hlf\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join('..','segment-utils'))\n",
    "import VideoAnnotationHelper as vah\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95bdbf8-797e-4163-8efb-776074dd64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"C:/Lumena\"\n",
    "train_data_folder = \"train_data\"\n",
    "sub_folders = [\"EL\", \"PC2\", \"PR\", \"EL_2\", \"CNMC\", \"CNMC.2023.11.07\", \"SS\", \"Bob\", \"PF\"]\n",
    "csv_filename = [\"cropped_256x256.csv\",\"cropped_256x256_original.csv\"]\n",
    "img_dir = [\"images_cropped_256x256\", \"images_cropped_256x256_original\"]\n",
    "mask_dir = [\"masksLined_cropped_256x256\",\"masksLined_cropped_256x256_original\"]\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 400\n",
    "cycles = 1 \n",
    "\n",
    "encoder_lr = 1e-4  \n",
    "regA_lr = 1e-4\n",
    "# regB_lr = 1e-4\n",
    "\n",
    "stop_encoder_requires_grad = False  \n",
    "stop_regA_requires_grad = False \n",
    "# stop_regB_requires_grad = True \n",
    "\n",
    "FullRange = False \n",
    "Gray = False\n",
    "ifTrain = True \n",
    "ifMSKCha = False \n",
    "\n",
    "observe_path=\"D:/test_dir\"\n",
    "\n",
    "old_model_path = \"//cgmqnap.clearguide.local/data/Needles/Lumena/models/hub_regression/model_cyc_1_ep_400_bs_32_lr_0.0001_20231228_T171234.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659f8ce6-49f2-4777-a7ed-b94f60a137ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = []\n",
    "labels = []\n",
    "\n",
    "for k in range(len(csv_filename)):\n",
    "    dfs = []\n",
    "    for ele in sub_folders:\n",
    "        df = pd.read_csv(parent_dir + \"/\" + train_data_folder + \"/\" + ele +\"/\" + csv_filename[k])\n",
    "        dfs.append(df)\n",
    "\n",
    "    for i in range(len(dfs)): \n",
    "        for name in zip(dfs[i][\"Images\"], dfs[i][\"Hub Y\"], dfs[i][\"Hub X\"], dfs[i][\"Tip Y\"], dfs[i][\"Tip X\"],dfs[i][\"Hub Present\"]): \n",
    "            if name[3]:\n",
    "                label_ele = [] \n",
    "                images_path.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + img_dir[k] + \"/\" + name[0])\n",
    "                label_ele.append(parent_dir + \"/\" + train_data_folder + \"/\" + sub_folders[i] + \"/\" + mask_dir[k] + \"/\" + name[0])\n",
    "                label_ele.append(name[1:])\n",
    "                labels.append(label_ele)\n",
    "      \n",
    "    \n",
    "X_train, X_val, y_train, y_val = train_test_split(images_path, labels, test_size = 0.2, random_state = 24)\n",
    "\n",
    "train_dataset = cid.Custom_ImageRegressor_Dataset2(X_train, y_train, ifgray = Gray, ifTrain = ifTrain, ifFullRange = FullRange, ifAddMskCha = ifMSKCha)\n",
    "val_dataset = cid.Custom_ImageRegressor_Dataset2(X_val, y_val, ifgray = Gray, ifTrain = ifTrain, ifFullRange = FullRange, ifAddMskCha = ifMSKCha)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True,num_workers=4,pin_memory = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False,num_workers=4,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63409d58-972c-49ff-8de7-36397b552abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder 'D:/test_dir/model_cyc_1_ep_400_bs_128_lr_0.0001_20240115_T105104'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model\" \n",
    "model_name += \"_cyc_\" + str(cycles) + \"_ep_\" + str(epochs) + \"_bs_\" + str(batch_size)\n",
    "model_name += \"_lr_\" + str(regA_lr)\n",
    "model_folder = model_name +  \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now())\n",
    " \n",
    "vah.createFolder(observe_path + \"/\"  + model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935a107e-b90b-4643-abbf-7cef2783879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "TipHubRegression                                                       --\n",
       "├─Sequential: 1-1                                                      --\n",
       "│    └─ConvBlockReLU: 2-1                                              --\n",
       "│    │    └─Sequential: 3-1                                            2,400\n",
       "│    └─ConvBlockReLU: 2-2                                              --\n",
       "│    │    └─Sequential: 3-2                                            12,592\n",
       "├─Sequential: 1-2                                                      --\n",
       "│    └─ConvBlockReLU: 2-3                                              --\n",
       "│    │    └─Sequential: 3-3                                            12,896\n",
       "│    └─ConvBlockReLU: 2-4                                              --\n",
       "│    │    └─Sequential: 3-4                                            25,696\n",
       "├─Sequential: 1-3                                                      --\n",
       "│    └─InceptionBlockReLU: 2-5                                         --\n",
       "│    │    └─Sequential: 3-5                                            15,440\n",
       "│    └─ResidualBlockReLU: 2-6                                          --\n",
       "│    │    └─Sequential: 3-6                                            37,056\n",
       "├─Sequential: 1-4                                                      --\n",
       "│    └─InceptionBlockReLU: 2-7                                         --\n",
       "│    │    └─Sequential: 3-7                                            61,088\n",
       "│    └─ResidualBlockReLU: 2-8                                          --\n",
       "│    │    └─Sequential: 3-8                                            147,840\n",
       "├─Sequential: 1-5                                                      --\n",
       "│    └─InceptionBlockReLU: 2-9                                         --\n",
       "│    │    └─Sequential: 3-9                                            61,088\n",
       "│    └─ResidualBlockReLU: 2-10                                         --\n",
       "│    │    └─Sequential: 3-10                                           147,840\n",
       "├─MaxPool2d: 1-6                                                       --\n",
       "├─Sequential: 1-7                                                      --\n",
       "│    └─Linear: 2-11                                                    16,777,728\n",
       "│    └─BatchNorm1d: 2-12                                               1,024\n",
       "│    └─ReLU: 2-13                                                      --\n",
       "│    └─Linear: 2-14                                                    131,328\n",
       "│    └─BatchNorm1d: 2-15                                               512\n",
       "│    └─ReLU: 2-16                                                      --\n",
       "│    └─Linear: 2-17                                                    8,224\n",
       "│    └─BatchNorm1d: 2-18                                               64\n",
       "│    └─ReLU: 2-19                                                      --\n",
       "│    └─Linear: 2-20                                                    66\n",
       "│    └─Sigmoid: 2-21                                                   --\n",
       "├─Sequential: 1-8                                                      --\n",
       "│    └─Linear: 2-22                                                    16,777,728\n",
       "│    └─BatchNorm1d: 2-23                                               1,024\n",
       "│    └─ReLU: 2-24                                                      --\n",
       "│    └─Linear: 2-25                                                    131,328\n",
       "│    └─BatchNorm1d: 2-26                                               512\n",
       "│    └─ReLU: 2-27                                                      --\n",
       "│    └─Linear: 2-28                                                    8,224\n",
       "│    └─BatchNorm1d: 2-29                                               64\n",
       "│    └─ReLU: 2-30                                                      --\n",
       "│    └─Linear: 2-31                                                    66\n",
       "│    └─Sigmoid: 2-32                                                   --\n",
       "├─Sequential: 1-9                                                      --\n",
       "│    └─Linear: 2-33                                                    16,777,728\n",
       "│    └─BatchNorm1d: 2-34                                               1,024\n",
       "│    └─ReLU: 2-35                                                      --\n",
       "│    └─Linear: 2-36                                                    131,328\n",
       "│    └─BatchNorm1d: 2-37                                               512\n",
       "│    └─ReLU: 2-38                                                      --\n",
       "│    └─Linear: 2-39                                                    8,224\n",
       "│    └─BatchNorm1d: 2-40                                               64\n",
       "│    └─ReLU: 2-41                                                      --\n",
       "│    └─Linear: 2-42                                                    33\n",
       "│    └─Sigmoid: 2-43                                                   --\n",
       "===============================================================================================\n",
       "Total params: 51,280,741\n",
       "Trainable params: 51,280,741\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cm.TipHubRegression().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20c0b86-9bfc-47d7-a3b9-09e9a6a6b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_model = torch.jit.load(old_model_path)\n",
    "# summary(old_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64297d1-095d-4614-9a4c-5f5c91107779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(old_model.state_dict(), strict=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b614fe5a-ba48-4785-8efe-80f45a3dae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. 0 conv1.0.conv_block.0.conv_block.0.weight\n",
      "NO. 1 conv1.0.conv_block.0.conv_block.0.bias\n",
      "NO. 2 conv1.0.conv_block.0.conv_block.1.weight\n",
      "NO. 3 conv1.0.conv_block.0.conv_block.1.bias\n",
      "NO. 4 conv1.1.conv_block.0.conv_block.0.weight\n",
      "NO. 5 conv1.1.conv_block.0.conv_block.0.bias\n",
      "NO. 6 conv1.1.conv_block.0.conv_block.1.weight\n",
      "NO. 7 conv1.1.conv_block.0.conv_block.1.bias\n",
      "NO. 8 conv2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 9 conv2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 10 conv2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 11 conv2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 12 conv2.1.conv_block.0.conv_block.0.weight\n",
      "NO. 13 conv2.1.conv_block.0.conv_block.0.bias\n",
      "NO. 14 conv2.1.conv_block.0.conv_block.1.weight\n",
      "NO. 15 conv2.1.conv_block.0.conv_block.1.bias\n",
      "NO. 16 conv3.0.layer.0.group1.conv_block.0.weight\n",
      "NO. 17 conv3.0.layer.0.group1.conv_block.0.bias\n",
      "NO. 18 conv3.0.layer.0.group1.conv_block.1.weight\n",
      "NO. 19 conv3.0.layer.0.group1.conv_block.1.bias\n",
      "NO. 20 conv3.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 21 conv3.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 22 conv3.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 23 conv3.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 24 conv3.0.layer.0.group2.1.conv_block.0.weight\n",
      "NO. 25 conv3.0.layer.0.group2.1.conv_block.0.bias\n",
      "NO. 26 conv3.0.layer.0.group2.1.conv_block.1.weight\n",
      "NO. 27 conv3.0.layer.0.group2.1.conv_block.1.bias\n",
      "NO. 28 conv3.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "NO. 29 conv3.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "NO. 30 conv3.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "NO. 31 conv3.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "NO. 32 conv3.0.layer.0.group3.1.conv_block.0.weight\n",
      "NO. 33 conv3.0.layer.0.group3.1.conv_block.0.bias\n",
      "NO. 34 conv3.0.layer.0.group3.1.conv_block.1.weight\n",
      "NO. 35 conv3.0.layer.0.group3.1.conv_block.1.bias\n",
      "NO. 36 conv3.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "NO. 37 conv3.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "NO. 38 conv3.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "NO. 39 conv3.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "NO. 40 conv3.0.layer.0.group4.1.conv_block.0.weight\n",
      "NO. 41 conv3.0.layer.0.group4.1.conv_block.0.bias\n",
      "NO. 42 conv3.0.layer.0.group4.1.conv_block.1.weight\n",
      "NO. 43 conv3.0.layer.0.group4.1.conv_block.1.bias\n",
      "NO. 44 conv3.1.residual_layer.0.residual_layer.0.weight\n",
      "NO. 45 conv3.1.residual_layer.0.residual_layer.0.bias\n",
      "NO. 46 conv3.1.residual_layer.0.residual_layer.1.weight\n",
      "NO. 47 conv3.1.residual_layer.0.residual_layer.1.bias\n",
      "NO. 48 conv4_h.0.layer.0.group1.conv_block.0.weight\n",
      "NO. 49 conv4_h.0.layer.0.group1.conv_block.0.bias\n",
      "NO. 50 conv4_h.0.layer.0.group1.conv_block.1.weight\n",
      "NO. 51 conv4_h.0.layer.0.group1.conv_block.1.bias\n",
      "NO. 52 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 53 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 54 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 55 conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 56 conv4_h.0.layer.0.group2.1.conv_block.0.weight\n",
      "NO. 57 conv4_h.0.layer.0.group2.1.conv_block.0.bias\n",
      "NO. 58 conv4_h.0.layer.0.group2.1.conv_block.1.weight\n",
      "NO. 59 conv4_h.0.layer.0.group2.1.conv_block.1.bias\n",
      "NO. 60 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "NO. 61 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "NO. 62 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "NO. 63 conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "NO. 64 conv4_h.0.layer.0.group3.1.conv_block.0.weight\n",
      "NO. 65 conv4_h.0.layer.0.group3.1.conv_block.0.bias\n",
      "NO. 66 conv4_h.0.layer.0.group3.1.conv_block.1.weight\n",
      "NO. 67 conv4_h.0.layer.0.group3.1.conv_block.1.bias\n",
      "NO. 68 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "NO. 69 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "NO. 70 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "NO. 71 conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "NO. 72 conv4_h.0.layer.0.group4.1.conv_block.0.weight\n",
      "NO. 73 conv4_h.0.layer.0.group4.1.conv_block.0.bias\n",
      "NO. 74 conv4_h.0.layer.0.group4.1.conv_block.1.weight\n",
      "NO. 75 conv4_h.0.layer.0.group4.1.conv_block.1.bias\n",
      "NO. 76 conv4_h.1.residual_layer.0.residual_layer.0.weight\n",
      "NO. 77 conv4_h.1.residual_layer.0.residual_layer.0.bias\n",
      "NO. 78 conv4_h.1.residual_layer.0.residual_layer.1.weight\n",
      "NO. 79 conv4_h.1.residual_layer.0.residual_layer.1.bias\n",
      "NO. 80 conv4_t.0.layer.0.group1.conv_block.0.weight\n",
      "NO. 81 conv4_t.0.layer.0.group1.conv_block.0.bias\n",
      "NO. 82 conv4_t.0.layer.0.group1.conv_block.1.weight\n",
      "NO. 83 conv4_t.0.layer.0.group1.conv_block.1.bias\n",
      "NO. 84 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "NO. 85 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "NO. 86 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "NO. 87 conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "NO. 88 conv4_t.0.layer.0.group2.1.conv_block.0.weight\n",
      "NO. 89 conv4_t.0.layer.0.group2.1.conv_block.0.bias\n",
      "NO. 90 conv4_t.0.layer.0.group2.1.conv_block.1.weight\n",
      "NO. 91 conv4_t.0.layer.0.group2.1.conv_block.1.bias\n",
      "NO. 92 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "NO. 93 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "NO. 94 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "NO. 95 conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "NO. 96 conv4_t.0.layer.0.group3.1.conv_block.0.weight\n",
      "NO. 97 conv4_t.0.layer.0.group3.1.conv_block.0.bias\n",
      "NO. 98 conv4_t.0.layer.0.group3.1.conv_block.1.weight\n",
      "NO. 99 conv4_t.0.layer.0.group3.1.conv_block.1.bias\n",
      "NO. 100 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "NO. 101 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "NO. 102 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "NO. 103 conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "NO. 104 conv4_t.0.layer.0.group4.1.conv_block.0.weight\n",
      "NO. 105 conv4_t.0.layer.0.group4.1.conv_block.0.bias\n",
      "NO. 106 conv4_t.0.layer.0.group4.1.conv_block.1.weight\n",
      "NO. 107 conv4_t.0.layer.0.group4.1.conv_block.1.bias\n",
      "NO. 108 conv4_t.1.residual_layer.0.residual_layer.0.weight\n",
      "NO. 109 conv4_t.1.residual_layer.0.residual_layer.0.bias\n",
      "NO. 110 conv4_t.1.residual_layer.0.residual_layer.1.weight\n",
      "NO. 111 conv4_t.1.residual_layer.0.residual_layer.1.bias\n",
      "NO. 112 fcah.0.weight\n",
      "NO. 113 fcah.0.bias\n",
      "NO. 114 fcah.1.weight\n",
      "NO. 115 fcah.1.bias\n",
      "NO. 116 fcah.3.weight\n",
      "NO. 117 fcah.3.bias\n",
      "NO. 118 fcah.4.weight\n",
      "NO. 119 fcah.4.bias\n",
      "NO. 120 fcah.6.weight\n",
      "NO. 121 fcah.6.bias\n",
      "NO. 122 fcah.7.weight\n",
      "NO. 123 fcah.7.bias\n",
      "NO. 124 fcah.9.weight\n",
      "NO. 125 fcah.9.bias\n",
      "NO. 126 fcat.0.weight\n",
      "NO. 127 fcat.0.bias\n",
      "NO. 128 fcat.1.weight\n",
      "NO. 129 fcat.1.bias\n",
      "NO. 130 fcat.3.weight\n",
      "NO. 131 fcat.3.bias\n",
      "NO. 132 fcat.4.weight\n",
      "NO. 133 fcat.4.bias\n",
      "NO. 134 fcat.6.weight\n",
      "NO. 135 fcat.6.bias\n",
      "NO. 136 fcat.7.weight\n",
      "NO. 137 fcat.7.bias\n",
      "NO. 138 fcat.9.weight\n",
      "NO. 139 fcat.9.bias\n",
      "NO. 140 fcb.0.weight\n",
      "NO. 141 fcb.0.bias\n",
      "NO. 142 fcb.1.weight\n",
      "NO. 143 fcb.1.bias\n",
      "NO. 144 fcb.3.weight\n",
      "NO. 145 fcb.3.bias\n",
      "NO. 146 fcb.4.weight\n",
      "NO. 147 fcb.4.bias\n",
      "NO. 148 fcb.6.weight\n",
      "NO. 149 fcb.6.bias\n",
      "NO. 150 fcb.7.weight\n",
      "NO. 151 fcb.7.bias\n",
      "NO. 152 fcb.9.weight\n",
      "NO. 153 fcb.9.bias\n"
     ]
    }
   ],
   "source": [
    " i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"NO.\", i, name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093a77f2-b653-4071-a8a8-07b4399c2874",
   "metadata": {},
   "outputs": [],
   "source": [
    " # lossFun1 = nn.MSELoss()\n",
    "#lossFun1 = lf.MSE \n",
    "LossFun1 = hlf.LineDistanceLoss() \n",
    "LossFun2 = lf.MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c446cf2-c3ff-4e82-bb24-01d351f9843f",
   "metadata": {},
   "outputs": [],
   "source": [
    " i = 0 \n",
    "encoder_list = []\n",
    "regressorA_list = []\n",
    "regressorB_list = [] \n",
    "\n",
    "for param in model.parameters(): \n",
    "    if i < 180: \n",
    "        if stop_encoder_requires_grad:\n",
    "            param.requires_grad = False \n",
    "        encoder_list.append(param)\n",
    "    else: \n",
    "        if stop_regA_requires_grad: \n",
    "            param.requires_grad = False \n",
    "        regressorA_list.append(param)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3db653-6c5d-4fc5-a9a1-9e48f551a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.conv_block.0.conv_block.0.weight\n",
      "conv1.0.conv_block.0.conv_block.0.bias\n",
      "conv1.0.conv_block.0.conv_block.1.weight\n",
      "conv1.0.conv_block.0.conv_block.1.bias\n",
      "conv1.1.conv_block.0.conv_block.0.weight\n",
      "conv1.1.conv_block.0.conv_block.0.bias\n",
      "conv1.1.conv_block.0.conv_block.1.weight\n",
      "conv1.1.conv_block.0.conv_block.1.bias\n",
      "conv2.0.conv_block.0.conv_block.0.weight\n",
      "conv2.0.conv_block.0.conv_block.0.bias\n",
      "conv2.0.conv_block.0.conv_block.1.weight\n",
      "conv2.0.conv_block.0.conv_block.1.bias\n",
      "conv2.1.conv_block.0.conv_block.0.weight\n",
      "conv2.1.conv_block.0.conv_block.0.bias\n",
      "conv2.1.conv_block.0.conv_block.1.weight\n",
      "conv2.1.conv_block.0.conv_block.1.bias\n",
      "conv3.0.layer.0.group1.conv_block.0.weight\n",
      "conv3.0.layer.0.group1.conv_block.0.bias\n",
      "conv3.0.layer.0.group1.conv_block.1.weight\n",
      "conv3.0.layer.0.group1.conv_block.1.bias\n",
      "conv3.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "conv3.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "conv3.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "conv3.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "conv3.0.layer.0.group2.1.conv_block.0.weight\n",
      "conv3.0.layer.0.group2.1.conv_block.0.bias\n",
      "conv3.0.layer.0.group2.1.conv_block.1.weight\n",
      "conv3.0.layer.0.group2.1.conv_block.1.bias\n",
      "conv3.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "conv3.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "conv3.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "conv3.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "conv3.0.layer.0.group3.1.conv_block.0.weight\n",
      "conv3.0.layer.0.group3.1.conv_block.0.bias\n",
      "conv3.0.layer.0.group3.1.conv_block.1.weight\n",
      "conv3.0.layer.0.group3.1.conv_block.1.bias\n",
      "conv3.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "conv3.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "conv3.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "conv3.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "conv3.0.layer.0.group4.1.conv_block.0.weight\n",
      "conv3.0.layer.0.group4.1.conv_block.0.bias\n",
      "conv3.0.layer.0.group4.1.conv_block.1.weight\n",
      "conv3.0.layer.0.group4.1.conv_block.1.bias\n",
      "conv3.1.residual_layer.0.residual_layer.0.weight\n",
      "conv3.1.residual_layer.0.residual_layer.0.bias\n",
      "conv3.1.residual_layer.0.residual_layer.1.weight\n",
      "conv3.1.residual_layer.0.residual_layer.1.bias\n",
      "conv4_h.0.layer.0.group1.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group1.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group1.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group1.conv_block.1.bias\n",
      "conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "conv4_h.0.layer.0.group2.1.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group2.1.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group2.1.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group2.1.conv_block.1.bias\n",
      "conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "conv4_h.0.layer.0.group3.1.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group3.1.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group3.1.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group3.1.conv_block.1.bias\n",
      "conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "conv4_h.0.layer.0.group4.1.conv_block.0.weight\n",
      "conv4_h.0.layer.0.group4.1.conv_block.0.bias\n",
      "conv4_h.0.layer.0.group4.1.conv_block.1.weight\n",
      "conv4_h.0.layer.0.group4.1.conv_block.1.bias\n",
      "conv4_h.1.residual_layer.0.residual_layer.0.weight\n",
      "conv4_h.1.residual_layer.0.residual_layer.0.bias\n",
      "conv4_h.1.residual_layer.0.residual_layer.1.weight\n",
      "conv4_h.1.residual_layer.0.residual_layer.1.bias\n",
      "conv4_t.0.layer.0.group1.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group1.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group1.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group1.conv_block.1.bias\n",
      "conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group2.0.conv_block.0.conv_block.1.bias\n",
      "conv4_t.0.layer.0.group2.1.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group2.1.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group2.1.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group2.1.conv_block.1.bias\n",
      "conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group3.0.conv_block.0.conv_block.1.bias\n",
      "conv4_t.0.layer.0.group3.1.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group3.1.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group3.1.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group3.1.conv_block.1.bias\n",
      "conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group4.0.conv_block.0.conv_block.1.bias\n",
      "conv4_t.0.layer.0.group4.1.conv_block.0.weight\n",
      "conv4_t.0.layer.0.group4.1.conv_block.0.bias\n",
      "conv4_t.0.layer.0.group4.1.conv_block.1.weight\n",
      "conv4_t.0.layer.0.group4.1.conv_block.1.bias\n",
      "conv4_t.1.residual_layer.0.residual_layer.0.weight\n",
      "conv4_t.1.residual_layer.0.residual_layer.0.bias\n",
      "conv4_t.1.residual_layer.0.residual_layer.1.weight\n",
      "conv4_t.1.residual_layer.0.residual_layer.1.bias\n",
      "fcah.0.weight\n",
      "fcah.0.bias\n",
      "fcah.1.weight\n",
      "fcah.1.bias\n",
      "fcah.3.weight\n",
      "fcah.3.bias\n",
      "fcah.4.weight\n",
      "fcah.4.bias\n",
      "fcah.6.weight\n",
      "fcah.6.bias\n",
      "fcah.7.weight\n",
      "fcah.7.bias\n",
      "fcah.9.weight\n",
      "fcah.9.bias\n",
      "fcat.0.weight\n",
      "fcat.0.bias\n",
      "fcat.1.weight\n",
      "fcat.1.bias\n",
      "fcat.3.weight\n",
      "fcat.3.bias\n",
      "fcat.4.weight\n",
      "fcat.4.bias\n",
      "fcat.6.weight\n",
      "fcat.6.bias\n",
      "fcat.7.weight\n",
      "fcat.7.bias\n",
      "fcat.9.weight\n",
      "fcat.9.bias\n",
      "fcb.0.weight\n",
      "fcb.0.bias\n",
      "fcb.1.weight\n",
      "fcb.1.bias\n",
      "fcb.3.weight\n",
      "fcb.3.bias\n",
      "fcb.4.weight\n",
      "fcb.4.bias\n",
      "fcb.6.weight\n",
      "fcb.6.bias\n",
      "fcb.7.weight\n",
      "fcb.7.bias\n",
      "fcb.9.weight\n",
      "fcb.9.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e9a3e35-078c-4bb4-b5f4-ed9b12509c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lr = 1e-5\n",
    "regA_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fcc477a-1c5f-4290-985b-26e074b52942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cycle:  1\n",
      "Epoch: 0  \tTraining Loss: 0.038832 \t Vali Loss: 0.067894 \t Exe Time: 18.033066sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T132308.pt\n",
      "Epoch: 1  \tTraining Loss: 0.046202 \t Vali Loss: 0.070302 \t Exe Time: 16.513996sec\n",
      "Epoch: 2  \tTraining Loss: 0.045626 \t Vali Loss: 0.068516 \t Exe Time: 16.739893sec\n",
      "Epoch: 3  \tTraining Loss: 0.056010 \t Vali Loss: 0.073477 \t Exe Time: 16.684041sec\n",
      "Epoch: 4  \tTraining Loss: 0.039011 \t Vali Loss: 0.065758 \t Exe Time: 16.454369sec\n",
      "Epoch: 5  \tTraining Loss: 0.036034 \t Vali Loss: 0.065554 \t Exe Time: 16.520090sec\n",
      "Epoch: 6  \tTraining Loss: 0.042905 \t Vali Loss: 0.075649 \t Exe Time: 16.339598sec\n",
      "Epoch: 7  \tTraining Loss: 0.048460 \t Vali Loss: 0.059764 \t Exe Time: 16.285261sec\n",
      "Epoch: 8  \tTraining Loss: 0.041594 \t Vali Loss: 0.069704 \t Exe Time: 16.235466sec\n",
      "Epoch: 9  \tTraining Loss: 0.058400 \t Vali Loss: 0.069033 \t Exe Time: 16.289102sec\n",
      "Epoch: 10  \tTraining Loss: 0.041542 \t Vali Loss: 0.066155 \t Exe Time: 16.393565sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T132553.pt\n",
      "Epoch: 11  \tTraining Loss: 0.050053 \t Vali Loss: 0.071556 \t Exe Time: 16.557461sec\n",
      "Epoch: 12  \tTraining Loss: 0.044375 \t Vali Loss: 0.076267 \t Exe Time: 16.465459sec\n",
      "Epoch: 13  \tTraining Loss: 0.055385 \t Vali Loss: 0.077299 \t Exe Time: 16.508107sec\n",
      "Epoch: 14  \tTraining Loss: 0.050495 \t Vali Loss: 0.071019 \t Exe Time: 16.359022sec\n",
      "Epoch: 15  \tTraining Loss: 0.038322 \t Vali Loss: 0.080173 \t Exe Time: 16.323815sec\n",
      "Epoch: 16  \tTraining Loss: 0.050728 \t Vali Loss: 0.080767 \t Exe Time: 16.508283sec\n",
      "Epoch: 17  \tTraining Loss: 0.041218 \t Vali Loss: 0.078151 \t Exe Time: 16.237564sec\n",
      "Epoch: 18  \tTraining Loss: 0.044221 \t Vali Loss: 0.072825 \t Exe Time: 16.377772sec\n",
      "Epoch: 19  \tTraining Loss: 0.044745 \t Vali Loss: 0.085696 \t Exe Time: 16.798180sec\n",
      "Epoch: 20  \tTraining Loss: 0.057400 \t Vali Loss: 0.063880 \t Exe Time: 16.125120sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T132838.pt\n",
      "Epoch: 21  \tTraining Loss: 0.059334 \t Vali Loss: 0.065897 \t Exe Time: 16.534959sec\n",
      "Epoch: 22  \tTraining Loss: 0.035471 \t Vali Loss: 0.072897 \t Exe Time: 16.322285sec\n",
      "Epoch: 23  \tTraining Loss: 0.050382 \t Vali Loss: 0.066551 \t Exe Time: 16.277092sec\n",
      "Epoch: 24  \tTraining Loss: 0.049541 \t Vali Loss: 0.081845 \t Exe Time: 16.543724sec\n",
      "Epoch: 25  \tTraining Loss: 0.047677 \t Vali Loss: 0.078160 \t Exe Time: 16.533115sec\n",
      "Epoch: 26  \tTraining Loss: 0.043903 \t Vali Loss: 0.070665 \t Exe Time: 16.446710sec\n",
      "Epoch: 27  \tTraining Loss: 0.065411 \t Vali Loss: 0.067351 \t Exe Time: 16.563932sec\n",
      "Epoch: 28  \tTraining Loss: 0.045993 \t Vali Loss: 0.075599 \t Exe Time: 16.181654sec\n",
      "Epoch: 29  \tTraining Loss: 0.039787 \t Vali Loss: 0.061828 \t Exe Time: 16.373550sec\n",
      "Epoch: 30  \tTraining Loss: 0.037664 \t Vali Loss: 0.078192 \t Exe Time: 16.581302sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T133122.pt\n",
      "Epoch: 31  \tTraining Loss: 0.049350 \t Vali Loss: 0.080310 \t Exe Time: 16.321986sec\n",
      "Epoch: 32  \tTraining Loss: 0.042937 \t Vali Loss: 0.070216 \t Exe Time: 16.617990sec\n",
      "Epoch: 33  \tTraining Loss: 0.042424 \t Vali Loss: 0.082917 \t Exe Time: 16.247634sec\n",
      "Epoch: 34  \tTraining Loss: 0.046290 \t Vali Loss: 0.065001 \t Exe Time: 16.133668sec\n",
      "Epoch: 35  \tTraining Loss: 0.045794 \t Vali Loss: 0.074888 \t Exe Time: 16.352712sec\n",
      "Epoch: 36  \tTraining Loss: 0.041328 \t Vali Loss: 0.070376 \t Exe Time: 16.593914sec\n",
      "Epoch: 37  \tTraining Loss: 0.044280 \t Vali Loss: 0.073907 \t Exe Time: 16.335007sec\n",
      "Epoch: 38  \tTraining Loss: 0.040704 \t Vali Loss: 0.076632 \t Exe Time: 16.241728sec\n",
      "Epoch: 39  \tTraining Loss: 0.044098 \t Vali Loss: 0.080678 \t Exe Time: 16.617764sec\n",
      "Epoch: 40  \tTraining Loss: 0.039913 \t Vali Loss: 0.074910 \t Exe Time: 16.233147sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T133407.pt\n",
      "Epoch: 41  \tTraining Loss: 0.053833 \t Vali Loss: 0.076511 \t Exe Time: 16.295338sec\n",
      "Epoch: 42  \tTraining Loss: 0.034738 \t Vali Loss: 0.081708 \t Exe Time: 16.391519sec\n",
      "Epoch: 43  \tTraining Loss: 0.041860 \t Vali Loss: 0.072277 \t Exe Time: 16.596079sec\n",
      "Epoch: 44  \tTraining Loss: 0.042787 \t Vali Loss: 0.071640 \t Exe Time: 16.516489sec\n",
      "Epoch: 45  \tTraining Loss: 0.036111 \t Vali Loss: 0.072940 \t Exe Time: 16.243959sec\n",
      "Epoch: 46  \tTraining Loss: 0.039769 \t Vali Loss: 0.074022 \t Exe Time: 16.265700sec\n",
      "Epoch: 47  \tTraining Loss: 0.066654 \t Vali Loss: 0.085539 \t Exe Time: 16.502326sec\n",
      "Epoch: 48  \tTraining Loss: 0.043064 \t Vali Loss: 0.062764 \t Exe Time: 16.466934sec\n",
      "Epoch: 49  \tTraining Loss: 0.044735 \t Vali Loss: 0.075581 \t Exe Time: 15.940388sec\n",
      "Epoch: 50  \tTraining Loss: 0.042867 \t Vali Loss: 0.079789 \t Exe Time: 16.683436sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T133651.pt\n",
      "Epoch: 51  \tTraining Loss: 0.051410 \t Vali Loss: 0.066919 \t Exe Time: 15.995533sec\n",
      "Epoch: 52  \tTraining Loss: 0.039296 \t Vali Loss: 0.082097 \t Exe Time: 16.444319sec\n",
      "Epoch: 53  \tTraining Loss: 0.047186 \t Vali Loss: 0.078187 \t Exe Time: 16.318144sec\n",
      "Epoch: 54  \tTraining Loss: 0.044432 \t Vali Loss: 0.073955 \t Exe Time: 16.197232sec\n",
      "Epoch: 55  \tTraining Loss: 0.036119 \t Vali Loss: 0.067599 \t Exe Time: 16.483601sec\n",
      "Epoch: 56  \tTraining Loss: 0.038692 \t Vali Loss: 0.080259 \t Exe Time: 16.093005sec\n",
      "Epoch: 57  \tTraining Loss: 0.054864 \t Vali Loss: 0.076305 \t Exe Time: 16.337966sec\n",
      "Epoch: 58  \tTraining Loss: 0.053425 \t Vali Loss: 0.076351 \t Exe Time: 15.932432sec\n",
      "Epoch: 59  \tTraining Loss: 0.035786 \t Vali Loss: 0.078521 \t Exe Time: 16.787393sec\n",
      "Epoch: 60  \tTraining Loss: 0.043227 \t Vali Loss: 0.070282 \t Exe Time: 16.269796sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T133934.pt\n",
      "Epoch: 61  \tTraining Loss: 0.037233 \t Vali Loss: 0.066001 \t Exe Time: 16.229384sec\n",
      "Epoch: 62  \tTraining Loss: 0.040450 \t Vali Loss: 0.073520 \t Exe Time: 16.465724sec\n",
      "Epoch: 63  \tTraining Loss: 0.042368 \t Vali Loss: 0.077620 \t Exe Time: 16.292486sec\n",
      "Epoch: 64  \tTraining Loss: 0.040245 \t Vali Loss: 0.084081 \t Exe Time: 15.980008sec\n",
      "Epoch: 65  \tTraining Loss: 0.042685 \t Vali Loss: 0.070854 \t Exe Time: 16.195418sec\n",
      "Epoch: 66  \tTraining Loss: 0.043591 \t Vali Loss: 0.079911 \t Exe Time: 16.447362sec\n",
      "Epoch: 67  \tTraining Loss: 0.051903 \t Vali Loss: 0.066169 \t Exe Time: 16.373970sec\n",
      "Epoch: 68  \tTraining Loss: 0.038536 \t Vali Loss: 0.075889 \t Exe Time: 16.476388sec\n",
      "Epoch: 69  \tTraining Loss: 0.037313 \t Vali Loss: 0.082657 \t Exe Time: 16.058120sec\n",
      "Epoch: 70  \tTraining Loss: 0.057196 \t Vali Loss: 0.079236 \t Exe Time: 16.249405sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T134218.pt\n",
      "Epoch: 71  \tTraining Loss: 0.047826 \t Vali Loss: 0.069029 \t Exe Time: 16.563067sec\n",
      "Epoch: 72  \tTraining Loss: 0.044132 \t Vali Loss: 0.080975 \t Exe Time: 16.033059sec\n",
      "Epoch: 73  \tTraining Loss: 0.038870 \t Vali Loss: 0.067980 \t Exe Time: 16.482710sec\n",
      "Epoch: 74  \tTraining Loss: 0.038307 \t Vali Loss: 0.077569 \t Exe Time: 16.110876sec\n",
      "Epoch: 75  \tTraining Loss: 0.043968 \t Vali Loss: 0.066903 \t Exe Time: 16.383099sec\n",
      "Epoch: 76  \tTraining Loss: 0.035978 \t Vali Loss: 0.077851 \t Exe Time: 16.245970sec\n",
      "Epoch: 77  \tTraining Loss: 0.045385 \t Vali Loss: 0.073792 \t Exe Time: 16.548802sec\n",
      "Epoch: 78  \tTraining Loss: 0.050446 \t Vali Loss: 0.066192 \t Exe Time: 16.109608sec\n",
      "Epoch: 79  \tTraining Loss: 0.044550 \t Vali Loss: 0.067603 \t Exe Time: 16.390557sec\n",
      "Epoch: 80  \tTraining Loss: 0.043084 \t Vali Loss: 0.066683 \t Exe Time: 16.219912sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T134501.pt\n",
      "Epoch: 81  \tTraining Loss: 0.046835 \t Vali Loss: 0.067739 \t Exe Time: 16.530798sec\n",
      "Epoch: 82  \tTraining Loss: 0.047155 \t Vali Loss: 0.065465 \t Exe Time: 16.191944sec\n",
      "Epoch: 83  \tTraining Loss: 0.038259 \t Vali Loss: 0.075344 \t Exe Time: 16.522949sec\n",
      "Epoch: 84  \tTraining Loss: 0.046510 \t Vali Loss: 0.079277 \t Exe Time: 16.391012sec\n",
      "Epoch: 85  \tTraining Loss: 0.039936 \t Vali Loss: 0.082122 \t Exe Time: 16.542654sec\n",
      "Epoch: 86  \tTraining Loss: 0.068734 \t Vali Loss: 0.066968 \t Exe Time: 16.256549sec\n",
      "Epoch: 87  \tTraining Loss: 0.043258 \t Vali Loss: 0.069102 \t Exe Time: 16.126503sec\n",
      "Epoch: 88  \tTraining Loss: 0.039691 \t Vali Loss: 0.069139 \t Exe Time: 16.490103sec\n",
      "Epoch: 89  \tTraining Loss: 0.039177 \t Vali Loss: 0.067024 \t Exe Time: 16.678450sec\n",
      "Epoch: 90  \tTraining Loss: 0.035899 \t Vali Loss: 0.078510 \t Exe Time: 16.374757sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T134746.pt\n",
      "Epoch: 91  \tTraining Loss: 0.048813 \t Vali Loss: 0.065835 \t Exe Time: 16.535931sec\n",
      "Epoch: 92  \tTraining Loss: 0.039413 \t Vali Loss: 0.070790 \t Exe Time: 15.997072sec\n",
      "Epoch: 93  \tTraining Loss: 0.058273 \t Vali Loss: 0.071519 \t Exe Time: 16.228191sec\n",
      "Epoch: 94  \tTraining Loss: 0.035709 \t Vali Loss: 0.075040 \t Exe Time: 16.042961sec\n",
      "Epoch: 95  \tTraining Loss: 0.042147 \t Vali Loss: 0.067671 \t Exe Time: 16.488826sec\n",
      "Epoch: 96  \tTraining Loss: 0.041310 \t Vali Loss: 0.078465 \t Exe Time: 16.517197sec\n",
      "Epoch: 97  \tTraining Loss: 0.048023 \t Vali Loss: 0.066232 \t Exe Time: 16.336277sec\n",
      "Epoch: 98  \tTraining Loss: 0.046127 \t Vali Loss: 0.084913 \t Exe Time: 16.441535sec\n",
      "Epoch: 99  \tTraining Loss: 0.050244 \t Vali Loss: 0.082515 \t Exe Time: 16.451792sec\n",
      "Epoch: 100  \tTraining Loss: 0.037389 \t Vali Loss: 0.067969 \t Exe Time: 16.155007sec\n",
      "Temprary model saved:  model_cyc_1_ep_400_bs_128_lr_0.0001_20240116_T135029.pt\n",
      "Epoch: 101  \tTraining Loss: 0.050488 \t Vali Loss: 0.080666 \t Exe Time: 15.988446sec\n",
      "Epoch: 102  \tTraining Loss: 0.051220 \t Vali Loss: 0.064509 \t Exe Time: 16.626162sec\n",
      "Epoch: 103  \tTraining Loss: 0.044832 \t Vali Loss: 0.085372 \t Exe Time: 16.530699sec\n",
      "Epoch: 104  \tTraining Loss: 0.044665 \t Vali Loss: 0.075569 \t Exe Time: 16.364195sec\n",
      "Epoch: 105  \tTraining Loss: 0.064937 \t Vali Loss: 0.065348 \t Exe Time: 16.414565sec\n",
      "Epoch: 106  \tTraining Loss: 0.047548 \t Vali Loss: 0.078256 \t Exe Time: 16.148816sec\n",
      "Epoch: 107  \tTraining Loss: 0.046737 \t Vali Loss: 0.068828 \t Exe Time: 16.482451sec\n",
      "Epoch: 108  \tTraining Loss: 0.045385 \t Vali Loss: 0.066763 \t Exe Time: 17.057773sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 21\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_yx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Xmen\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(cycles):\n",
    "\n",
    "    print(\"Training Cycle: \", j+1)\n",
    "\n",
    "    optimizer = torch.optim.Adam([{\"params\":encoder_list, \"lr\":encoder_lr},\n",
    "                                  #{\"params\":regressorA_list, \"lr\":regA_lr},\n",
    "                                  #{\"params\":regressorB_list, \"lr\":regB_lr}\n",
    "                                 ])#, weight_decay = 1e-5)\n",
    "    \n",
    "    \n",
    "#     early_stopping = th.EarlyStopping(patience = 10, min_delta = 0.001)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0        \n",
    "        start_time = time.time() \n",
    "        \n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            images, true_yx, true_p= data \n",
    "            timex = time.process_time()\n",
    "            images = images.to(device)\n",
    "            true_yx = true_yx.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_yx, pred_p = model(images)\n",
    "            # pred_yx = model(images)\n",
    "            \n",
    "            loss = LossFun1.forward(pred_yx.float(),true_yx.float()) + LossFun2(pred_yx.float(),true_yx.float())\n",
    "            loss.backward()\n",
    "      \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss\n",
    "\n",
    "            \n",
    "        model.eval()    \n",
    "        for data in val_loader: \n",
    "            \n",
    "            images, true_yx, true_p= data\n",
    "            images = images.to(device)\n",
    "            true_yx = true_yx.to(device)\n",
    "\n",
    "            with torch.no_grad(): \n",
    "                pred_yx, pred_p = model(images)\n",
    "                # pred_yx = model(images)\n",
    "                loss = LossFun1.forward(pred_yx.float(),true_yx.float()) + LossFun2(pred_yx.float(),true_yx.float())\n",
    "                # loss.backward()\n",
    "     \n",
    "            val_loss += loss\n",
    "\n",
    "        \n",
    "        train_loss = train_loss/len(train_loader)    \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        \n",
    "        \n",
    "        print('Epoch: {}  \\tTraining Loss: {:.6f} \\t Vali Loss: {:.6f} \\t Exe Time: {:.6f}sec'.format(\n",
    "        epoch, \n",
    "        train_loss, \n",
    "        val_loss,\n",
    "        time.time() - start_time))\n",
    "\n",
    "#         stop = early_stopping.early_stop(val_loss, model)\n",
    "#         if stop: \n",
    "#             model = early_stopping.get_model() \n",
    "#             print(\"Early Stopping because of regressor val loss\")\n",
    "#             break \n",
    "        \n",
    "        if epoch % 10 == 0: \n",
    " \n",
    "            model_script = torch.jit.script(model)\n",
    "            temp_name = model_name + \"_{:%Y%m%d_T%H%M%S}\".format(datetime.datetime.now()) + \".pt\"\n",
    "            model_script.save(observe_path + \"/\"  + model_folder + \"/\" + temp_name)\n",
    "            print(\"Temprary model saved: \", temp_name)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d8251-339e-4492-8a58-c27fcfea7b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
